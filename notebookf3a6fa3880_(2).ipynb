{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.7.12",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "colab": {
      "name": "notebookf3a6fa3880 (2).ipynb",
      "provenance": []
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "5eddabf98c18417b81e22ebf6a330cc1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_6aaa62a5c1b042e6887deba22d8bfb75",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_909acff990ca4b958f9b852f32310f80",
              "IPY_MODEL_41a484bbeac84f4cb6bc2ebb9a0dc72c",
              "IPY_MODEL_0f00f02a2f3248638ff87a1c28f51bc9"
            ]
          }
        },
        "6aaa62a5c1b042e6887deba22d8bfb75": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "909acff990ca4b958f9b852f32310f80": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_187d454ecbf849b8b68bc4cc7088e393",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "‚Äã",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_079375f382b4401f821766e6f50333b7"
          }
        },
        "41a484bbeac84f4cb6bc2ebb9a0dc72c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_69976f23fa994e2bbdc9e0114eb3fca4",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 5,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 5,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_e17bec2e0772435b82ae8fd173e62271"
          }
        },
        "0f00f02a2f3248638ff87a1c28f51bc9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_257de7cab68849689317b27a77440e6f",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "‚Äã",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 5/5 [17:19&lt;00:00, 224.14s/it]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d314dd9a7ae942fabea043896892f754"
          }
        },
        "187d454ecbf849b8b68bc4cc7088e393": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "079375f382b4401f821766e6f50333b7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "69976f23fa994e2bbdc9e0114eb3fca4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "e17bec2e0772435b82ae8fd173e62271": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "257de7cab68849689317b27a77440e6f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d314dd9a7ae942fabea043896892f754": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# –í–≤–µ–¥–µ–Ω–∏–µ –≤ –≥–ª—É–±–∏–Ω–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ, –§–ö–ù –í–®–≠\n",
        "\n",
        "## –î–æ–º–∞—à–Ω–µ–µ –∑–∞–¥–∞–Ω–∏–µ 3. –û–±—Ä–∞–±–æ—Ç–∫–∞ —Ç–µ–∫—Å—Ç–æ–≤.\n",
        "\n",
        "### –û–±—â–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è\n",
        "\n",
        "–î–∞—Ç–∞ –≤—ã–¥–∞—á–∏: 13.01.2022\n",
        "\n",
        "–ú—è–≥–∫–∏–π –¥–µ–¥–ª–∞–π–Ω: 23:59MSK 6.02.2022\n",
        "\n",
        "–ñ–µ—Å—Ç–∫–∏–π –¥–µ–¥–ª–∞–π–Ω: 23:59MSK 10.02.2022\n",
        "\n",
        "–û—Ü–µ–Ω–∫–∞ –ø–æ—Å–ª–µ —à—Ç—Ä–∞—Ñ–∞ –ø–æ—Å–ª–µ –º—è–≥–∫–æ–≥–æ –¥–µ–¥–ª–∞–π–Ω–∞ –≤—ã—á–∏—Å–ª—è–µ—Ç—Å—è –ø–æ —Ñ–æ—Ä–º—É–ª–µ $M_{penalty} = M_{full} \\cdot 0.85^{t/1440}$, –≥–¥–µ $M_{full}$ ‚Äî –ø–æ–ª–Ω–∞—è –æ—Ü–µ–Ω–∫–∞ –∑–∞ —Ä–∞–±–æ—Ç—É –±–µ–∑ —É—á–µ—Ç–∞ —à—Ç—Ä–∞—Ñ–∞, –∞ $t$ ‚Äî –≤—Ä–µ–º—è –≤ –º–∏–Ω—É—Ç–∞—Ö, –ø—Ä–æ—à–µ–¥—à–µ–µ –ø–æ—Å–ª–µ –º—è–≥–∫–æ–≥–æ –¥–µ–¥–ª–∞–π–Ω–∞ (–æ–∫—Ä—É–≥–ª–µ–Ω–∏–µ –¥–æ –¥–≤—É—Ö —Ü–∏—Ñ—Ä –ø–æ—Å–ª–µ –∑–∞–ø—è—Ç–æ–π). –¢–∞–∫–∏–º –æ–±—Ä–∞–∑–æ–º, —Å–ø—É—Å—Ç—è –ø–µ—Ä–≤—ã–µ —Å—É—Ç–∫–∏ –ø–æ—Å–ª–µ –º—è–≥–∫–æ–≥–æ –¥–µ–¥–ª–∞–π–Ω–∞ –≤—ã –Ω–µ –º–æ–∂–µ—Ç–µ –ø–æ–ª—É—á–∏—Ç—å –æ—Ü–µ–Ω–∫—É –≤—ã—à–µ 8.5, –∞ –µ—Å–ª–∏ —Å–¥–∞—Ç—å –ø–µ—Ä–µ–¥ —Å–∞–º—ã–º –∂–µ—Å—Ç–∫–∏–º –¥–µ–¥–ª–∞–π–Ω–æ–º, —Ç–æ –≤–∞—à –º–∞–∫—Å–∏–º—É–º ‚Äî 5.22 –±–∞–ª–ª–∞.\n",
        "\n",
        "### –û—Ü–µ–Ω–∏–≤–∞–Ω–∏–µ –∏ —à—Ç—Ä–∞—Ñ—ã\n",
        "\n",
        "–ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ –¥–æ–ø—É—Å—Ç–∏–º–∞—è –æ—Ü–µ–Ω–∫–∞ –∑–∞ —Ä–∞–±–æ—Ç—É ‚Äî 10 –±–∞–ª–ª–æ–≤. –°–¥–∞–≤–∞—Ç—å –∑–∞–¥–∞–Ω–∏–µ –ø–æ—Å–ª–µ —É–∫–∞–∑–∞–Ω–Ω–æ–≥–æ —Å—Ä–æ–∫–∞ —Å–¥–∞—á–∏ –Ω–µ–ª—å–∑—è.\n",
        "\n",
        "–ó–∞–¥–∞–Ω–∏–µ –≤—ã–ø–æ–ª–Ω—è–µ—Ç—Å—è —Å–∞–º–æ—Å—Ç–æ—è—Ç–µ–ª—å–Ω–æ. ¬´–ü–æ—Ö–æ–∂–∏–µ¬ª —Ä–µ—à–µ–Ω–∏—è —Å—á–∏—Ç–∞—é—Ç—Å—è –ø–ª–∞–≥–∏–∞—Ç–æ–º –∏ –≤—Å–µ –∑–∞–¥–µ–π—Å—Ç–≤–æ–≤–∞–Ω–Ω—ã–µ —Å—Ç—É–¥–µ–Ω—Ç—ã (–≤ —Ç–æ–º —á–∏—Å–ª–µ —Ç–µ, —É –∫–æ–≥–æ —Å–ø–∏—Å–∞–ª–∏) –Ω–µ –º–æ–≥—É—Ç –ø–æ–ª—É—á–∏—Ç—å –∑–∞ –Ω–µ–≥–æ –±–æ–ª—å—à–µ 0 –±–∞–ª–ª–æ–≤. –ï—Å–ª–∏ –≤—ã –Ω–∞—à–ª–∏ —Ä–µ—à–µ–Ω–∏–µ –∫–∞–∫–æ–≥–æ-—Ç–æ –∏–∑ –∑–∞–¥–∞–Ω–∏–π (–∏–ª–∏ –µ–≥–æ —á–∞—Å—Ç—å) –≤ –æ—Ç–∫—Ä—ã—Ç–æ–º –∏—Å—Ç–æ—á–Ω–∏–∫–µ, –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ —É–∫–∞–∑–∞—Ç—å —Å—Å—ã–ª–∫—É –Ω–∞ —ç—Ç–æ—Ç –∏—Å—Ç–æ—á–Ω–∏–∫ –≤ –æ—Ç–¥–µ–ª—å–Ω–æ–º –±–ª–æ–∫–µ –≤ –∫–æ–Ω—Ü–µ –≤–∞—à–µ–π —Ä–∞–±–æ—Ç—ã (—Å–∫–æ—Ä–µ–µ –≤—Å–µ–≥–æ –≤—ã –±—É–¥–µ—Ç–µ –Ω–µ –µ–¥–∏–Ω—Å—Ç–≤–µ–Ω–Ω—ã–º, –∫—Ç–æ —ç—Ç–æ –Ω–∞—à–µ–ª, –ø–æ—ç—Ç–æ–º—É —á—Ç–æ–±—ã –∏—Å–∫–ª—é—á–∏—Ç—å –ø–æ–¥–æ–∑—Ä–µ–Ω–∏–µ –≤ –ø–ª–∞–≥–∏–∞—Ç–µ, –Ω–µ–æ–±—Ö–æ–¥–∏–º–∞ —Å—Å—ã–ª–∫–∞ –Ω–∞ –∏—Å—Ç–æ—á–Ω–∏–∫).\n",
        "\n",
        "–ù–µ—ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–∞—è —Ä–µ–∞–ª–∏–∑–∞—Ü–∏—è –∫–æ–¥–∞ –º–æ–∂–µ—Ç –Ω–µ–≥–∞—Ç–∏–≤–Ω–æ –æ—Ç—Ä–∞–∑–∏—Ç—å—Å—è –Ω–∞ –æ—Ü–µ–Ω–∫–µ. –¢–∞–∫–∂–µ –æ—Ü–µ–Ω–∫–∞ –º–æ–∂–µ—Ç –±—ã—Ç—å —Å–Ω–∏–∂–µ–Ω–∞ –∑–∞ –ø–ª–æ—Ö–æ —á–∏—Ç–∞–µ–º—ã–π –∫–æ–¥ –∏ –ø–ª–æ—Ö–æ –æ—Ñ–æ—Ä–º–ª–µ–Ω–Ω—ã–µ –≥—Ä–∞—Ñ–∏–∫–∏. –í—Å–µ –æ—Ç–≤–µ—Ç—ã –¥–æ–ª–∂–Ω—ã —Å–æ–ø—Ä–æ–≤–æ–∂–¥–∞—Ç—å—Å—è –∫–æ–¥–æ–º –∏–ª–∏ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏—è–º–∏ –æ —Ç–æ–º, –∫–∞–∫ –æ–Ω–∏ –±—ã–ª–∏ –ø–æ–ª—É—á–µ–Ω—ã.\n",
        "\n",
        "### –û –∑–∞–¥–∞–Ω–∏–∏\n",
        "\n",
        "–í –¥–∞–Ω–Ω–æ–º –¥–æ–º–∞—à–Ω–µ–º –∑–∞–¥–∞–Ω–∏–∏ –≤–∞–º –ø—Ä–µ–¥—Å—Ç–æ–∏—Ç –ø—Ä–µ–¥—Å–∫–∞–∑—ã–≤–∞—Ç—å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫—É—é –æ—Ü–µ–Ω–∫—É –æ—Ç–µ–ª—è –ø–æ —Ç–µ–∫—Å—Ç—É –æ—Ç–∑—ã–≤–∞. –ù—É–∂–Ω–æ –æ–±—É—á–∏—Ç—å—Å—è –Ω–∞ –¥–∞–Ω–Ω—ã—Ö —Å –∫—ç–≥–≥–ª–∞ –∏ –∑–∞—Å–ª–∞—Ç—å –≤ [—Å–æ—Ä–µ–≤–Ω–æ–≤–∞–Ω–∏–µ](https://www.kaggle.com/t/3e8fa6cec6d048bf8e93fb72e441d88c) –ø—Ä–µ–¥–∏–∫—Ç. –ü–æ —Ç–æ–π –∂–µ —Å—Å—ã–ª–∫–µ –º–æ–∂–µ—Ç–µ —Å–∫–∞—á–∞—Ç—å –¥–∞–Ω–Ω—ã–µ.\n",
        "\n",
        "–ú—ã —Å–æ–±—Ä–∞–ª–∏ –¥–ª—è –≤–∞—Å –æ—Ç–∑—ã–≤—ã –ø–æ 1500 –æ—Ç–µ–ª—è–º –∏–∑ —Å–æ–≤–µ—Ä—à–µ–Ω–Ω–æ —Ä–∞–∑–Ω—ã—Ö —É–≥–æ–ª–∫–æ–≤ –º–∏—Ä–∞. –ß—Ç–æ —ç—Ç–æ –∑–∞ –æ—Ç–µ–ª–∏ - —Å–µ–∫—Ä–µ—Ç. –í–∞–º –¥–∞–Ω —Ç–µ–∫—Å—Ç –æ—Ç–∑—ã–≤–∞ –∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–∞—è –æ—Ü–µ–Ω–∫–∞ –æ—Ç–µ–ª—è. –í–∞—à–∞ –∑–∞–¥–∞—á–∞ - –Ω–∞—É—á–∏—Ç—å—Å—è –ø—Ä–µ–¥—Å–∫–∞–∑—ã–≤–∞—Ç—å –æ—Ü–µ–Ω–∫—É –æ—Ç–µ–ª—è –ø–æ –æ—Ç–∑—ã–≤—É.\n",
        "\n",
        "–ì–ª–∞–≤–Ω–∞—è –º–µ—Ç—Ä–∏–∫–∞ - Mean Absolute Error (MAE). –í–æ –≤—Å–µ—Ö —á–∞—Å—Ç—è—Ö –¥–æ–º–∞—à–Ω–µ–π —Ä–∞–±–æ—Ç—ã –≤–∞–º –Ω—É–∂–Ω–æ –ø–æ–ª—É—á–∏—Ç—å –∑–Ω–∞—á–µ–Ω–∏–µ MAE –Ω–µ –ø—Ä–µ–≤—ã—à–∞—é—â–µ–µ 0.92 –Ω–∞ –ø—É–±–ª–∏—á–Ω–æ–º –ª–∏–¥–µ—Ä–±–æ—Ä–¥–µ. –í –ø—Ä–æ—Ç–∏–≤–Ω–æ–º —Å–ª—É—á–∞–µ –º—ã –±—É–¥–µ–º –≤—ã–Ω—É–∂–¥–µ–Ω—ã –Ω–µ –∑–∞—Å—á–∏—Ç–∞—Ç—å –∑–∞–¥–∞–Ω–∏–µ :( \n",
        "\n",
        "#### –ü—Ä–æ –¥–∞–Ω–Ω—ã–µ:\n",
        "–ö–∞–∂–¥–æ–µ —Ä–µ–≤—å—é —Å–æ—Å—Ç–æ–∏—Ç –∏–∑ –¥–≤—É—Ö —Ç–µ–∫—Å—Ç–æ–≤: positive –∏ negative - –ø–ª—é—Å—ã –∏ –º–∏–Ω—É—Å—ã –æ—Ç–µ–ª—è. –í —Å—Ç–æ–ª–±—Ü–µ score –Ω–∞—Ö–æ–¥–∏—Ç—Å—è –æ—Ü–µ–Ω–∫–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è - –≤–µ—â–µ—Å—Ç–≤–µ–Ω–Ω–æ–µ —á–∏—Å–ª–æ 0 –¥–æ 10. –í–∞–º –Ω—É–∂–Ω–æ –∏–∑–≤–ª–µ—á—å –ø—Ä–∏–∑–Ω–∞–∫–∏ –∏–∑ —ç—Ç–∏—Ö —Ç–µ–∫—Å—Ç–æ–≤ –∏ –ø—Ä–µ–¥—Å–∫–∞–∑–∞—Ç—å –ø–æ –Ω–∏–º –æ—Ü–µ–Ω–∫—É.\n",
        "\n",
        "–î–ª—è –ª–æ–∫–∞–ª—å–Ω–æ–≥–æ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω–Ω–æ–µ —Ä–∞–∑–±–∏–µ–Ω–∏–µ –Ω–∞ —Ç—Ä–µ–π–Ω –∏ —Ç–µ—Å—Ç.\n",
        "\n",
        "Good luck & have fun! üí™"
      ],
      "metadata": {
        "id": "OCfOAvvpXHaH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from tqdm.notebook import tqdm"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-02-04T18:54:03.576909Z",
          "iopub.execute_input": "2022-02-04T18:54:03.577436Z",
          "iopub.status.idle": "2022-02-04T18:54:05.145344Z",
          "shell.execute_reply.started": "2022-02-04T18:54:03.577346Z",
          "shell.execute_reply": "2022-02-04T18:54:05.144266Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F9b67bjwvfAE",
        "outputId": "fa69537b-2c4d-4668-8601-7268b6471726"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.10.2+cu102\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –ª—é–±—ã–µ –¥–∞–Ω–Ω—ã–µ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è –∫—Ä–æ–º–µ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω–Ω—ã—Ö –æ—Ä–≥–∞–Ω–∏–∑–∞—Ç–æ—Ä–∞–º–∏ —Å—Ç—Ä–æ–≥–æ –∑–∞–ø—Ä–µ—â–µ–Ω–æ. –í –ø–æ—Å–ª–µ–¥–Ω–µ–π —á–∞—Å—Ç–∏ –º–æ–∂–Ω–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –ø—Ä–µ–¥–æ–±—É—á–µ–Ω–Ω—ã–µ –º–æ–¥–µ–ª–∏ –∏–∑ –±–∏–±–ª–∏–æ—Ç–µ–∫–∏ `transformers`."
      ],
      "metadata": {
        "id": "T6Ej16t1XHaM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "PATH_TO_TRAIN_DATA = 'drive/MyDrive/data/train.csv'"
      ],
      "metadata": {
        "id": "g96zAM-fwSJS"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv(PATH_TO_TRAIN_DATA)\n",
        "df.sample(10)"
      ],
      "metadata": {
        "id": "6kJRM6ZUXHaO",
        "outputId": "b624a839-518b-4456-dfcf-eaf2bdedf6cd",
        "execution": {
          "iopub.status.busy": "2022-02-04T18:54:05.156238Z",
          "iopub.execute_input": "2022-02-04T18:54:05.157252Z",
          "iopub.status.idle": "2022-02-04T18:54:06.054300Z",
          "shell.execute_reply.started": "2022-02-04T18:54:05.157193Z",
          "shell.execute_reply": "2022-02-04T18:54:06.053460Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 362
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-68489965-7770-4cdb-9b30-bfb48c3a5145\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review_id</th>\n",
              "      <th>negative</th>\n",
              "      <th>positive</th>\n",
              "      <th>score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2050</th>\n",
              "      <td>0577cd13e8245a98e0635e0f7f4ff5ee</td>\n",
              "      <td>Had a slight problem with our meal at the in ...</td>\n",
              "      <td>Reception area very beautiful and Made a grea...</td>\n",
              "      <td>9.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31907</th>\n",
              "      <td>520bcdce8faf17e9544cb337d8051138</td>\n",
              "      <td>Carpeted floor aged bathroom cobwebs at the c...</td>\n",
              "      <td>The location and the breakfast is great espec...</td>\n",
              "      <td>6.3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>90725</th>\n",
              "      <td>e82d1266336ae99076f306a6c451d9b6</td>\n",
              "      <td>11 steps down from roadway to reception No as...</td>\n",
              "      <td>Location to shops and to Metro line</td>\n",
              "      <td>7.1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99321</th>\n",
              "      <td>fe3d60970724ac44f25a25373e48d861</td>\n",
              "      <td>overpriced</td>\n",
              "      <td>Good location very close to tram stop direct ...</td>\n",
              "      <td>7.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31526</th>\n",
              "      <td>512424ee53f417ce5525a31054d0bbbe</td>\n",
              "      <td>It would have been nice to know that in this ...</td>\n",
              "      <td>It was good it was near the central line just...</td>\n",
              "      <td>8.8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35809</th>\n",
              "      <td>5c119f8f25ba0b347b9a944d80317b03</td>\n",
              "      <td>Bad greeting highly overpriced and window bli...</td>\n",
              "      <td>Nothing</td>\n",
              "      <td>4.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75472</th>\n",
              "      <td>c1632e67adf46ab9c0c84f730cd0b2eb</td>\n",
              "      <td>Poor room for the Hilton</td>\n",
              "      <td>No Positive</td>\n",
              "      <td>7.1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15688</th>\n",
              "      <td>28a9061e07f487c9fafe2823e6b32e83</td>\n",
              "      <td>My booking was described as one for a deluxe ...</td>\n",
              "      <td>No traffic noise but doors banging elsewhere ...</td>\n",
              "      <td>6.3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8858</th>\n",
              "      <td>17173c60b8bd669e729afbcbc7afd84b</td>\n",
              "      <td>Rooms are so small and when we asked the staf...</td>\n",
              "      <td>Location was good</td>\n",
              "      <td>2.9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>76494</th>\n",
              "      <td>c3df5c647b22ea84c89dd5cf2be82b77</td>\n",
              "      <td>Finishes not the best</td>\n",
              "      <td>Handy location nice staff innovative room layout</td>\n",
              "      <td>8.8</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-68489965-7770-4cdb-9b30-bfb48c3a5145')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-68489965-7770-4cdb-9b30-bfb48c3a5145 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-68489965-7770-4cdb-9b30-bfb48c3a5145');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                              review_id  ... score\n",
              "2050   0577cd13e8245a98e0635e0f7f4ff5ee  ...   9.2\n",
              "31907  520bcdce8faf17e9544cb337d8051138  ...   6.3\n",
              "90725  e82d1266336ae99076f306a6c451d9b6  ...   7.1\n",
              "99321  fe3d60970724ac44f25a25373e48d861  ...   7.5\n",
              "31526  512424ee53f417ce5525a31054d0bbbe  ...   8.8\n",
              "35809  5c119f8f25ba0b347b9a944d80317b03  ...   4.2\n",
              "75472  c1632e67adf46ab9c0c84f730cd0b2eb  ...   7.1\n",
              "15688  28a9061e07f487c9fafe2823e6b32e83  ...   6.3\n",
              "8858   17173c60b8bd669e729afbcbc7afd84b  ...   2.9\n",
              "76494  c3df5c647b22ea84c89dd5cf2be82b77  ...   8.8\n",
              "\n",
              "[10 rows x 4 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "–ü—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ —Ç–µ–∫—Å—Ç–∞ –º–æ–∂–µ—Ç —Å–∫–∞–∑—ã–≤–∞—Ç—å—Å—è –Ω–∞ –∫–∞—á–µ—Å—Ç–≤–µ –≤–∞—à–µ–π –º–æ–¥–µ–ª–∏.\n",
        "–°–¥–µ–ª–∞–µ–º –Ω–µ–±–æ–ª—å—à–æ–π –ø—Ä–µ–ø—Ä–æ—Ü–µ—Å—Å–∏–Ω–≥ —Ç–µ–∫—Å—Ç–æ–≤: —É–¥–∞–ª–∏–º –∑–Ω–∞–∫–∏ –ø—Ä–µ–ø–∏–Ω–∞–Ω–∏—è, –ø—Ä–∏–≤–µ–¥–µ–º –≤—Å–µ —Å–ª–æ–≤–∞ –∫ –Ω–∏–∂–Ω–µ–º—É —Ä–µ–≥–∏—Å—Ç—Ä—É. \n",
        "–û–¥–Ω–∞–∫–æ –º–æ–∂–Ω–æ –Ω–µ –æ–≥—Ä–∞–Ω–∏—á–∏–≤–∞—Ç—å—Å—è —ç—Ç–∏–º –Ω–∞–±–æ—Ä–æ–º –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–π. –ü–æ–¥—É–º–∞–π—Ç–µ, —á—Ç–æ –µ—â–µ –º–æ–∂–Ω–æ —Å–¥–µ–ª–∞—Ç—å —Å —Ç–µ–∫—Å—Ç–∞–º–∏, —á—Ç–æ–±—ã –ø–æ–º–æ—á—å –±—É–¥—É—â–∏–º –º–æ–¥–µ–ª—è–º? –î–æ–±–∞–≤—å—Ç–µ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏—è, –∫–æ—Ç–æ—Ä—ã–µ –º–æ–≥–ª–∏ –±—ã –ø–æ–º–æ—á—å –ø–æ –≤–∞—à–µ–º—É –º–Ω–µ–Ω–∏—é."
      ],
      "metadata": {
        "id": "bpLk8dXBXHaP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "–¢–∞–∫–∂–µ –º—ã –¥–æ–±–∞–≤–∏–ª–∏ —Ä–∞–∑–±–∏–µ–Ω–∏–µ —Ç–µ–∫—Å—Ç–æ–≤ –Ω–∞ —Ç–æ–∫–µ–Ω—ã. –¢–µ–ø–µ—Ä—å –∫–∞–∂–¥–∞—è —Å—Ç—Ä–æ–∫–∞-—Ä–µ–≤—å—é —Å—Ç–∞–ª–∞ –º–∞—Å—Å–∏–≤–æ–º —Ç–æ–∫–µ–Ω–æ–≤."
      ],
      "metadata": {
        "id": "SfkhII5AXHaP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import string\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.tokenize import word_tokenize\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('stopwords')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_L3zVmsu0ymI",
        "outputId": "eb6ab5a5-8b0c-41dd-e111-6b44e474a350"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def process_text(text):\n",
        "    return [word for word in word_tokenize(text.lower()) if word not in string.punctuation]\n",
        "\n",
        "from nltk.stem import WordNetLemmatizer \n",
        "\n",
        "def process_lower(text):\n",
        "    return text.lower()\n",
        "#     return lemmatizer.lemmatize(text.lower())"
      ],
      "metadata": {
        "id": "tv-gbEKGXHaQ",
        "execution": {
          "iopub.status.busy": "2022-02-04T18:54:06.063045Z",
          "iopub.execute_input": "2022-02-04T18:54:06.063307Z",
          "iopub.status.idle": "2022-02-04T18:54:07.782030Z",
          "shell.execute_reply.started": "2022-02-04T18:54:06.063276Z",
          "shell.execute_reply": "2022-02-04T18:54:07.781268Z"
        },
        "trusted": true
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "s = \"Now bats are leaving their trees, They're joining the call, Seven Satanic Hell Preachers Heading for the hall. \\\n",
        "Bringing a blood of a newborn child, Got to succeed, if not it's Satan's fall\"\n",
        "lemmatizer = WordNetLemmatizer()\n",
        " \n",
        "stop_words = set(stopwords.words('english') + [ \"'s\", \"'re\"]) - {'no'}\n",
        "# stop_words = set(['a', 'an', 'the', \"'s\", 'to', \"'re\", 'is', 'are', 'be', 'been', 'was', 'were', 'has', 'had', 'have'])\n",
        "def process_text_advanced(text):\n",
        "    text = [lemmatizer.lemmatize(word) for word in word_tokenize(text.lower()) \n",
        "            if word not in string.punctuation and word not in stop_words]\n",
        "    return ' '.join(text)\n",
        "process_text_advanced(s)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-02-04T18:54:07.783119Z",
          "iopub.execute_input": "2022-02-04T18:54:07.783755Z",
          "iopub.status.idle": "2022-02-04T18:54:10.125380Z",
          "shell.execute_reply.started": "2022-02-04T18:54:07.783712Z",
          "shell.execute_reply": "2022-02-04T18:54:10.124755Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "T2yHjx42vfAK",
        "outputId": "24696e47-b56b-461f-a450-0b657165dbbd"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'bat leaving tree joining call seven satanic hell preacher heading hall bringing blood newborn child got succeed satan fall'"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['negative'] = df['negative'].apply(process_text_advanced)\n",
        "df['positive'] = df['positive'].apply(process_text_advanced)"
      ],
      "metadata": {
        "id": "-X1bXhROXHaQ",
        "execution": {
          "iopub.status.busy": "2022-02-04T18:54:10.126666Z",
          "iopub.execute_input": "2022-02-04T18:54:10.127057Z",
          "iopub.status.idle": "2022-02-04T18:55:12.867281Z",
          "shell.execute_reply.started": "2022-02-04T18:54:10.127008Z",
          "shell.execute_reply": "2022-02-04T18:55:12.865969Z"
        },
        "trusted": true
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "df_train, df_test = train_test_split(df, random_state=1412) # <- –¥–ª—è –ª–æ–∫–∞–ª—å–Ω–æ–≥–æ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è\n",
        "y_train = df_train['score'].to_numpy()\n",
        "y_test = df_test['score'].to_numpy()"
      ],
      "metadata": {
        "id": "MewBIvp9XHaQ",
        "execution": {
          "iopub.status.busy": "2022-02-04T18:55:12.868354Z",
          "iopub.execute_input": "2022-02-04T18:55:12.868594Z",
          "iopub.status.idle": "2022-02-04T18:55:12.909594Z",
          "shell.execute_reply.started": "2022-02-04T18:55:12.868546Z",
          "shell.execute_reply": "2022-02-04T18:55:12.908809Z"
        },
        "trusted": true
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### –ß–∞—Å—Ç—å 1. 1 –±–∞–ª–ª"
      ],
      "metadata": {
        "id": "3gu1EIc3XHaR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "–û–±—É—á–∏—Ç–µ –ª–æ–≥–∏—Å—Ç–∏—á–µ—Å–∫—É—é –∏–ª–∏ –ª–∏–Ω–µ–π–Ω—É—é —Ä–µ–≥—Ä–µ—Å—Å–∏—é –Ω–∞ TF-IDF –≤–µ–∫—Ç–æ—Ä–∞—Ö —Ç–µ–∫—Å—Ç–æ–≤."
      ],
      "metadata": {
        "id": "DM7ZD9gyXHaR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.linear_model import Ridge\n",
        "from sklearn.linear_model import Lasso\n",
        "from sklearn.metrics import mean_absolute_error as MAE"
      ],
      "metadata": {
        "id": "2x4yCjh8XHaR",
        "execution": {
          "iopub.status.busy": "2022-02-04T18:55:12.910563Z",
          "iopub.execute_input": "2022-02-04T18:55:12.911336Z",
          "iopub.status.idle": "2022-02-04T18:55:12.917700Z",
          "shell.execute_reply.started": "2022-02-04T18:55:12.911295Z",
          "shell.execute_reply": "2022-02-04T18:55:12.916943Z"
        },
        "trusted": true
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "–ü—Ä–µ–¥—Å–∫–∞–∂–∏—Ç–µ —ç—Ç–æ–π –º–æ–¥–µ–ª—å—é —Ç–µ—Å—Ç–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ –∏–∑ [—Å–æ—Ä–µ–≤–Ω–æ–≤–∞–Ω–∏—è](https://www.kaggle.com/t/3e8fa6cec6d048bf8e93fb72e441d88c) –∏ —Å–¥–µ–ª–∞–π—Ç–µ —Å–∞–±–º–∏—Ç. –ö–∞–∫–æ–π —É –≤–∞—Å –ø–æ–ª—É—á–∏–ª—Å—è —Å–∫–æ—Ä? –ü—Ä–∏–∫—Ä–µ–ø–∏—Ç–µ —Å–∫—Ä–∏–Ω—à–æ—Ç –∏–∑ –∫—ç–≥–≥–ª–∞."
      ],
      "metadata": {
        "id": "0CufFcfHXhuo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# data_train = (df_train['negative'] + ' ' + df_train['positive']).tolist()\n",
        "# data_test = (df_test['negative'] + ' ' + df_test['positive']).tolist()\n",
        "# –í–º–µ—Å—Ç–æ —ç—Ç–æ–≥–æ –º–Ω–µ –ø–æ—Å–æ–≤–µ—Ç–æ–≤–∞–ª–∏ –¥–µ–ª–∞—Ç—å —Ç–∞–∫:"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-02-04T18:55:12.921470Z",
          "iopub.execute_input": "2022-02-04T18:55:12.921786Z",
          "iopub.status.idle": "2022-02-04T18:55:12.931531Z",
          "shell.execute_reply.started": "2022-02-04T18:55:12.921753Z",
          "shell.execute_reply": "2022-02-04T18:55:12.930205Z"
        },
        "trusted": true,
        "id": "pvkLOQfPvfAN"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def pdsp(data):\n",
        "    return pd.DataFrame.sparse.from_spmatrix(data)\n",
        "\n",
        "def transform_fragments(v1, v2, data: list, mode=1):\n",
        "    '''\n",
        "        mode = 1: fitting + transform, input - train / +test data\n",
        "        mode = 2: transform, input - only train or test data\n",
        "    '''\n",
        "    if mode == 2:\n",
        "        assert (len(data) == 1)\n",
        "    \n",
        "    return_data = []\n",
        "    for ind, d in enumerate(data):\n",
        "        if ind > 0 or mode == 2:\n",
        "            data_pos = v1.transform(d['positive'])\n",
        "            data_neg = v2.transform(d['negative'])\n",
        "        else:\n",
        "            data_pos = v1.fit_transform(d['positive'])\n",
        "            data_neg = v2.fit_transform(d['negative'])\n",
        "            \n",
        "        data_ = pd.concat([pdsp(data_pos), pdsp(data_neg)], axis=1, ignore_index=True)\n",
        "        return_data += [data_.sparse.to_coo().tocsr()]\n",
        "    \n",
        "    return return_data, v1, v2"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-02-04T18:55:12.933004Z",
          "iopub.execute_input": "2022-02-04T18:55:12.933302Z",
          "iopub.status.idle": "2022-02-04T18:55:12.946270Z",
          "shell.execute_reply.started": "2022-02-04T18:55:12.933263Z",
          "shell.execute_reply": "2022-02-04T18:55:12.945129Z"
        },
        "trusted": true,
        "id": "KcIoP0SVvfAO"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vec1, vec2 = TfidfVectorizer(), TfidfVectorizer()\n",
        "X, vec1, vec2 = transform_fragments(vec1, vec2, [df_train, df_test])\n",
        "X_train, X_test = X[0], X[1]\n",
        "assert X_train.shape[1] == X_test.shape[1]"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-02-04T18:55:12.948025Z",
          "iopub.execute_input": "2022-02-04T18:55:12.948621Z",
          "iopub.status.idle": "2022-02-04T18:55:29.694427Z",
          "shell.execute_reply.started": "2022-02-04T18:55:12.948545Z",
          "shell.execute_reply": "2022-02-04T18:55:29.693631Z"
        },
        "trusted": true,
        "id": "N7dip7avvfAO"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# –í—ã–¥–∞–≤–∞–ª–æ –æ—à–∏–±–∫—É, –ø–æ—ç—Ç–æ–º—É –ø–µ—Ä–µ–≤–µ–ª –≤ 100-–±–∞–ª–ª—å–Ω—É—é\n",
        "logreg = LogisticRegression(solver=\"liblinear\").fit(X_train, (y_train * 10).astype(int))\n",
        "rig = Ridge().fit(X_train, y_train)\n",
        "lasso = Lasso().fit(X_train, y_train)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-02-04T18:55:29.695679Z",
          "iopub.execute_input": "2022-02-04T18:55:29.695921Z",
          "iopub.status.idle": "2022-02-04T18:58:08.642893Z",
          "shell.execute_reply.started": "2022-02-04T18:55:29.695890Z",
          "shell.execute_reply": "2022-02-04T18:58:08.641637Z"
        },
        "trusted": true,
        "id": "LS7XqKYdvfAO"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_rig = rig.predict(X_test)\n",
        "y_pred_lass = lasso.predict(X_test)\n",
        "y_pred_lr = logreg.predict(X_test)\n",
        "\n",
        "print('MAE for Ridge:', MAE(y_test, y_pred_rig))\n",
        "print('MAE for Lasso:', MAE(y_test, y_pred_lass))\n",
        "print('MAE for LogReg:', MAE(y_test, y_pred_lr / 10))\n",
        "\n",
        "# MAE for Ridge: 0.8427509194337326\n",
        "# MAE for Lasso: 1.3166713036799997\n",
        "# MAE for LogReg: 0.9546279999999999"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-02-04T18:58:08.644774Z",
          "iopub.execute_input": "2022-02-04T18:58:08.646784Z",
          "iopub.status.idle": "2022-02-04T18:58:08.769162Z",
          "shell.execute_reply.started": "2022-02-04T18:58:08.646717Z",
          "shell.execute_reply": "2022-02-04T18:58:08.768511Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mt_wXGUrvfAP",
        "outputId": "01533a41-e3b3-4087-c0ea-7e2690eb5820"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MAE for Ridge: 0.8427509194337326\n",
            "MAE for Lasso: 1.3166713036799997\n",
            "MAE for LogReg: 0.9546279999999999\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "`Ridge`-—Ä–µ–≥—Ä–µ—Å—Å–∏—è —Å–ø—Ä–∞–≤–∏–ª–∞—Å—å –ª—É—á—à–µ –≤—Å–µ—Ö."
      ],
      "metadata": {
        "id": "aIBwKt0uvfAP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "PATH_TO_TEST_DATA = 'drive/MyDrive/data/test.csv'\n",
        "for_submit_df = pd.read_csv(PATH_TO_TEST_DATA)\n",
        "for_submit_df['negative'] = for_submit_df['negative'].apply(process_text_advanced)\n",
        "for_submit_df['positive'] = for_submit_df['positive'].apply(process_text_advanced)\n",
        "\n",
        "X_subm, _, _ = transform_fragments(vec1, vec2, [for_submit_df], mode=2)\n",
        "\n",
        "y_pred_rig_subm = rig.predict(X_subm[0])\n",
        "for_submit_df.drop(columns=['negative', 'positive'], inplace=True)\n",
        "for_submit_df['score'] = y_pred_rig_subm"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-02-04T18:58:08.770364Z",
          "iopub.execute_input": "2022-02-04T18:58:08.770784Z",
          "iopub.status.idle": "2022-02-04T18:58:28.810314Z",
          "shell.execute_reply.started": "2022-02-04T18:58:08.770753Z",
          "shell.execute_reply": "2022-02-04T18:58:28.809281Z"
        },
        "trusted": true,
        "id": "fgpD64s2vfAP"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for_submit_df.to_csv('sumbit.csv', index=False)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-02-04T18:58:28.811711Z",
          "iopub.execute_input": "2022-02-04T18:58:28.812017Z",
          "iopub.status.idle": "2022-02-04T18:58:28.918394Z",
          "shell.execute_reply.started": "2022-02-04T18:58:28.811975Z",
          "shell.execute_reply": "2022-02-04T18:58:28.917535Z"
        },
        "trusted": true,
        "id": "1RBNmuk_vfAP"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "del X, vec1, vec2, X_train, X_test, y_pred_lr, y_pred_lass, y_pred_rig, X_subm, for_submit_df"
      ],
      "metadata": {
        "id": "GksOGVqqAsA2"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### –ß–∞—Å—Ç—å 2. 2 –±–∞–ª–ª–∞"
      ],
      "metadata": {
        "id": "E-4Zve40XHaS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "–û–±—É—á–∏—Ç–µ –ª–æ–≥–∏—Å—Ç–∏—á–µ—Å–∫—É—é –∏–ª–∏ –ª–∏–Ω–µ–π–Ω—É—é —Ä–µ–≥—Ä–µ—Å—Å–∏—é –Ω–∞ —É—Å—Ä–µ–¥–Ω–µ–Ω–Ω—ã—Ö Word2Vec –≤–µ–∫—Ç–æ—Ä–∞—Ö. "
      ],
      "metadata": {
        "id": "cYFL-5yFXHaS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install --upgrade gensim"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3SeqkWXC1dxA",
        "outputId": "8f850bc4-b5c2-48d9-b198-9e724fab2ece"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gensim in /usr/local/lib/python3.7/dist-packages (4.1.2)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.7/dist-packages (from gensim) (5.2.1)\n",
            "Requirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.7/dist-packages (from gensim) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.17.0 in /usr/local/lib/python3.7/dist-packages (from gensim) (1.19.5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gensim\n",
        "from gensim.models import Word2Vec"
      ],
      "metadata": {
        "id": "jpcCEhBDXHaS",
        "execution": {
          "iopub.status.busy": "2022-02-04T18:58:28.919677Z",
          "iopub.execute_input": "2022-02-04T18:58:28.920477Z",
          "iopub.status.idle": "2022-02-04T18:58:30.148083Z",
          "shell.execute_reply.started": "2022-02-04T18:58:28.920436Z",
          "shell.execute_reply": "2022-02-04T18:58:30.147294Z"
        },
        "trusted": true
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_train['negative'] = df_train['negative'].apply(process_text)\n",
        "df_train['positive'] = df_train['positive'].apply(process_text)\n",
        "df_test['negative'] = df_test['negative'].apply(process_text)\n",
        "df_test['positive'] = df_test['positive'].apply(process_text)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-02-04T18:58:30.149790Z",
          "iopub.execute_input": "2022-02-04T18:58:30.150123Z",
          "iopub.status.idle": "2022-02-04T18:59:12.363963Z",
          "shell.execute_reply.started": "2022-02-04T18:58:30.150081Z",
          "shell.execute_reply": "2022-02-04T18:59:12.362563Z"
        },
        "trusted": true,
        "id": "UoK4J98lvfAQ"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "w2v_model_pos = Word2Vec(df_train['positive'], window=7, epochs=7)\n",
        "w2v_model_neg = Word2Vec(df_train['negative'], window=7, epochs=7)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-02-04T18:59:12.365419Z",
          "iopub.execute_input": "2022-02-04T18:59:12.365727Z",
          "iopub.status.idle": "2022-02-04T18:59:22.791012Z",
          "shell.execute_reply.started": "2022-02-04T18:59:12.365694Z",
          "shell.execute_reply": "2022-02-04T18:59:22.790124Z"
        },
        "trusted": true,
        "id": "cyaOEzOUvfAQ"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from scipy.sparse.csr import csr_matrix\n",
        "# –ü–æ–∑–∞–∏–º—Å—Ç–æ–≤–∞–Ω–æ –∏–∑ https://habr.com/ru/company/ods/blog/329410/\n",
        "class mean_vectorizer():\n",
        "    def __init__(self, w2v_model):\n",
        "        self.w2v_model = w2v_model\n",
        "\n",
        "    def fit(self, X):\n",
        "        self.w2v_dict = dict(zip(self.w2v_model.wv.index_to_key, self.w2v_model.wv.vectors))\n",
        "        self.dim = self.w2v_model.wv.vectors.shape[1]\n",
        "        return self \n",
        "\n",
        "    def transform(self, X):\n",
        "        return csr_matrix([\n",
        "            np.mean([self.w2v_dict[w] for w in words if w in self.w2v_dict] \n",
        "                or [np.zeros(self.dim)], axis=0) for words in X\n",
        "        ])\n",
        "    \n",
        "    def fit_transform(self, X):\n",
        "        self = self.fit(X)\n",
        "        return self.transform(X)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-02-04T18:59:22.792279Z",
          "iopub.execute_input": "2022-02-04T18:59:22.792523Z",
          "iopub.status.idle": "2022-02-04T18:59:22.801984Z",
          "shell.execute_reply.started": "2022-02-04T18:59:22.792494Z",
          "shell.execute_reply": "2022-02-04T18:59:22.801112Z"
        },
        "trusted": true,
        "id": "VNvyvqRcvfAQ"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vec1, vec2 = mean_vectorizer(w2v_model_pos), mean_vectorizer(w2v_model_neg)\n",
        "X, vec1, vec2 = transform_fragments(vec1, vec2, [df_train, df_test])"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-02-04T18:59:22.803380Z",
          "iopub.execute_input": "2022-02-04T18:59:22.803645Z",
          "iopub.status.idle": "2022-02-04T18:59:32.513994Z",
          "shell.execute_reply.started": "2022-02-04T18:59:22.803606Z",
          "shell.execute_reply": "2022-02-04T18:59:32.513062Z"
        },
        "trusted": true,
        "id": "qJKfQq8NvfAR"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_quality(X_train, y_train, X_test, y_test, alert=False, alpha=1.):\n",
        "    rig = Ridge(alpha=alpha).fit(X_train, y_train)\n",
        "    y_pred_rig = rig.predict(X_test)\n",
        "    y_pred_rig_train = rig.predict(X_train)\n",
        "    q_rig = MAE(y_test, y_pred_rig)\n",
        "    q_rig_train = MAE(y_train, y_pred_rig_train)\n",
        "    \n",
        "    if alert:\n",
        "        print('Test MAE for Ridge:', q_rig)\n",
        "        print('Train MAE for Ridge:', q_rig_train)\n",
        "        \n",
        "    return q_rig"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-02-04T18:59:32.515408Z",
          "iopub.execute_input": "2022-02-04T18:59:32.515642Z",
          "iopub.status.idle": "2022-02-04T18:59:32.521304Z",
          "shell.execute_reply.started": "2022-02-04T18:59:32.515614Z",
          "shell.execute_reply": "2022-02-04T18:59:32.520374Z"
        },
        "trusted": true,
        "id": "EHx4BLeFvfAR"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "_ = get_quality(X[0], y_train, X[1], y_test, alert=True)\n",
        "# Test MAE for Ridge: 0.9604130193301033\n",
        "# Train MAE for Ridge: 0.9530745706699796"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-02-04T18:59:32.522772Z",
          "iopub.execute_input": "2022-02-04T18:59:32.523021Z",
          "iopub.status.idle": "2022-02-04T18:59:36.409147Z",
          "shell.execute_reply.started": "2022-02-04T18:59:32.522994Z",
          "shell.execute_reply": "2022-02-04T18:59:36.408001Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bgl7pduRvfAR",
        "outputId": "ddf1dc3b-1f36-4799-d8ca-0fac36a43e91"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test MAE for Ridge: 0.9623280538662836\n",
            "Train MAE for Ridge: 0.9542300129739026\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "–£—Å—Ä–µ–¥–Ω—è—è w2v –≤–µ–∫—Ç–æ—Ä–∞, –º—ã –ø—Ä–µ–¥–ø–æ–ª–∞–≥–∞–µ–º, —á—Ç–æ –∫–∞–∂–¥–æ–µ —Å–ª–æ–≤–æ –∏–º–µ–µ—Ç —Ä–∞–≤–Ω–æ—Ü–µ–Ω–Ω—ã–π –≤–∫–ª–∞–¥ –≤ —Å–º—ã—Å–ª –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è, –æ–¥–Ω–∞–∫–æ —ç—Ç–æ –º–æ–∂–µ—Ç –±—ã—Ç—å –Ω–µ —Å–æ–≤—Å–µ–º —Ç–∞–∫. –¢–µ–ø–µ—Ä—å –ø–æ–ø—Ä–æ–±—É–π—Ç–µ –≤–æ—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å—Å—è –¥—Ä—É–≥–æ–π –∫–æ–Ω—Ü–µ–ø—Ü–∏–µ–π –∏ –ø–µ—Ä–µ–≤–∑–≤–µ—Å–∏—Ç—å —Å–ª–æ–≤–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ –∏—Ç–æ–≥–æ–≤–æ–≥–æ —ç–º–±–µ–¥–¥–∏–Ω–≥–∞ —Ç–µ–∫—Å—Ç–∞. –í –∫–∞—á–µ—Å—Ç–≤–µ –≤–µ—Å–æ–≤ –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ IDF (Inverse document frequency)"
      ],
      "metadata": {
        "id": "KWrIciGxXHaS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import defaultdict\n",
        "\n",
        "class tfidf_vectorizer():\n",
        "    def __init__(self, w2v_model):\n",
        "        self.w2v_model = w2v_model\n",
        "        self.word2weight = None\n",
        "\n",
        "    def fit(self, X):\n",
        "        self.w2v_dict = dict(zip(self.w2v_model.wv.index_to_key, self.w2v_model.wv.vectors))\n",
        "        self.dim = self.w2v_model.wv.vectors.shape[1]\n",
        "        \n",
        "        tfidf = TfidfVectorizer(analyzer=lambda x: x)\n",
        "        tfidf = tfidf.fit(X)\n",
        "        max_idf = max(tfidf.idf_)\n",
        "        self.word2weight = defaultdict(\n",
        "            lambda: max_idf,\n",
        "            [(w, tfidf.idf_[i]) for w, i in tfidf.vocabulary_.items()]\n",
        "        )\n",
        "\n",
        "        return self\n",
        "\n",
        "    def transform(self, X):\n",
        "        return csr_matrix([\n",
        "                np.mean([self.w2v_dict[w] * self.word2weight[w]\n",
        "                         for w in words if w in self.w2v_dict] or\n",
        "                        [np.zeros(self.dim)], axis=0) for words in X\n",
        "            ])\n",
        "\n",
        "    def fit_transform(self, X):\n",
        "        self = self.fit(X)\n",
        "        return self.transform(X)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-02-04T18:59:36.411093Z",
          "iopub.execute_input": "2022-02-04T18:59:36.411435Z",
          "iopub.status.idle": "2022-02-04T18:59:36.424234Z",
          "shell.execute_reply.started": "2022-02-04T18:59:36.411363Z",
          "shell.execute_reply": "2022-02-04T18:59:36.422925Z"
        },
        "trusted": true,
        "id": "3a4zuSy3vfAR"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vec1, vec2 = tfidf_vectorizer(w2v_model_pos), tfidf_vectorizer(w2v_model_neg)\n",
        "X, vec1, vec2 = transform_fragments(vec1, vec2, [df_train, df_test])"
      ],
      "metadata": {
        "id": "mQSuuLP9XHaS",
        "execution": {
          "iopub.status.busy": "2022-02-04T18:59:36.425951Z",
          "iopub.execute_input": "2022-02-04T18:59:36.426799Z",
          "iopub.status.idle": "2022-02-04T19:00:03.352153Z",
          "shell.execute_reply.started": "2022-02-04T18:59:36.426746Z",
          "shell.execute_reply": "2022-02-04T19:00:03.351096Z"
        },
        "trusted": true
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "_ = get_quality(X[0], y_train, X[1], y_test, alert=True)\n",
        "# Test MAE for Ridge: 0.9620847507977837\n",
        "# Train MAE for Ridge: 0.954713798120569"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-02-04T19:00:03.353765Z",
          "iopub.execute_input": "2022-02-04T19:00:03.354007Z",
          "iopub.status.idle": "2022-02-04T19:00:07.521533Z",
          "shell.execute_reply.started": "2022-02-04T19:00:03.353978Z",
          "shell.execute_reply": "2022-02-04T19:00:07.520519Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iCya78R2vfAS",
        "outputId": "82ec068c-087b-4756-a6af-4e9cd1f8d3a3"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test MAE for Ridge: 0.9641755105243773\n",
            "Train MAE for Ridge: 0.9556134385176874\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "–ü—Ä–æ–≤–µ–¥–∏—Ç–µ —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç—ã —Å —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å—é —ç–º–±–µ–¥–¥–∏–Ω–≥–∞. –î–ª—è –∫–∞–∂–¥–æ–≥–æ –∏–∑ –¥–≤—É—Ö –º–µ—Ç–æ–¥–æ–≤ –ø–æ—Å—Ç—Ä–æ–π—Ç–µ –≥—Ä–∞—Ñ–∏–∫ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –∫–∞—á–µ—Å—Ç–≤–∞ –º–æ–¥–µ–ª–∏ –æ—Ç —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç–∏ —ç–º–±–µ–¥–¥–∏–Ω–≥–∞. "
      ],
      "metadata": {
        "id": "4s-6HQo0XHaT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "emb_dims = [i * 50 for i in range(6, 11)]\n",
        "results = {\n",
        "    'mean': [],\n",
        "    'tfidf': []\n",
        "}\n",
        "\n",
        "for dim in tqdm(emb_dims):\n",
        "    \n",
        "    w2v_model_pos = Word2Vec(df_train['positive'], window=30, vector_size=dim)\n",
        "    w2v_model_neg = Word2Vec(df_train['negative'], window=30, vector_size=dim)\n",
        "    \n",
        "    vec1, vec2 = mean_vectorizer(w2v_model_pos), mean_vectorizer(w2v_model_neg)\n",
        "    X, _, _ = transform_fragments(vec1, vec2, [df_train, df_test])\n",
        "    mv_q_rig = get_quality(X[0], y_train, X[1], y_test)\n",
        "    results['mean'].append(mv_q_rig)\n",
        "    \n",
        "    vec1, vec2 = tfidf_vectorizer(w2v_model_pos), tfidf_vectorizer(w2v_model_neg)\n",
        "    X, _, _ = transform_fragments(vec1, vec2, [df_train, df_test])\n",
        "    tfidf_q_rig = get_quality(X[0], y_train, X[1], y_test)\n",
        "    results['tfidf'].append(tfidf_q_rig)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-02-04T19:00:07.523129Z",
          "iopub.execute_input": "2022-02-04T19:00:07.523359Z",
          "iopub.status.idle": "2022-02-04T19:24:58.327477Z",
          "shell.execute_reply.started": "2022-02-04T19:00:07.523331Z",
          "shell.execute_reply": "2022-02-04T19:24:58.326458Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "5eddabf98c18417b81e22ebf6a330cc1",
            "6aaa62a5c1b042e6887deba22d8bfb75",
            "909acff990ca4b958f9b852f32310f80",
            "41a484bbeac84f4cb6bc2ebb9a0dc72c",
            "0f00f02a2f3248638ff87a1c28f51bc9",
            "187d454ecbf849b8b68bc4cc7088e393",
            "079375f382b4401f821766e6f50333b7",
            "69976f23fa994e2bbdc9e0114eb3fca4",
            "e17bec2e0772435b82ae8fd173e62271",
            "257de7cab68849689317b27a77440e6f",
            "d314dd9a7ae942fabea043896892f754"
          ]
        },
        "id": "uAy5dRMIvfAS",
        "outputId": "70e6f165-0b5e-4b8d-d3b8-9356e5210526"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5eddabf98c18417b81e22ebf6a330cc1",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "  0%|          | 0/5 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fig, ax1 = plt.subplots(nrows=1, ncols=1, figsize=(16, 5))\n",
        "ax1.plot(emb_dims, results['mean'], color='lime', label='mean')\n",
        "ax1.plot(emb_dims, results['tfidf'], color='blue', label='IDF mean')\n",
        "ax1.set_xlabel('embegging size')\n",
        "ax1.set_ylabel('MAE')\n",
        "ax1.set_title('Embegging size - MAE')\n",
        "ax1.legend(shadow=False, fontsize=14)\n",
        "plt.show()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-02-04T19:24:58.331313Z",
          "iopub.execute_input": "2022-02-04T19:24:58.331592Z",
          "iopub.status.idle": "2022-02-04T19:24:58.631994Z",
          "shell.execute_reply.started": "2022-02-04T19:24:58.331544Z",
          "shell.execute_reply": "2022-02-04T19:24:58.631101Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 350
        },
        "id": "fQZ9mH3JvfAS",
        "outputId": "3acf4201-e202-41e4-cc38-1dc8731e826c"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1152x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results['tfidf'][np.argmin(results['tfidf'])], emb_dims[np.argmin(results['tfidf'])], \\\n",
        "results['mean'][np.argmin(results['mean'])], emb_dims[np.argmin(results['mean'])]"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-02-04T19:24:58.633168Z",
          "iopub.execute_input": "2022-02-04T19:24:58.633410Z",
          "iopub.status.idle": "2022-02-04T19:24:58.641558Z",
          "shell.execute_reply.started": "2022-02-04T19:24:58.633380Z",
          "shell.execute_reply": "2022-02-04T19:24:58.640702Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DATIU9dovfAT",
        "outputId": "5b6bc9ad-c004-45fa-f742-3d487c522dd3"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.9412967344933015, 500, 0.9506049075731786, 500)"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### –°–¥–µ–ª–∞–π—Ç–µ –≤—ã–≤–æ–¥—ã:\n",
        "–Ø –ø–æ–∑–∞–ø—É—Å–∫–∞–ª –º–Ω–æ–≥–æ —Ä–∞–∑. –û–ø—Ç–∏–º–∞–ª—å–Ω—ã–π —Ä–∞–∑–º–µ—Ä –≤–æ –º–Ω–æ–≥–æ–º –∑–∞–≤–∏—Å–∏—Ç –æ—Ç –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤, –Ω–∞–ø—Ä–∏–º–µ—Ä, –æ—Ç —Ä–∞–∑–º–µ—Ä–∞ –æ–∫–Ω–∞ `window`. –¢–µ–Ω–¥–µ–Ω—Ü–∏–∏ —Ç–æ–∂–µ –º–æ–≥—É—Ç —Ä–∞–∑–ª–∏—á–∞—Ç—å—Å—è, –Ω–æ —è –∑–∞–º–µ—Ç–∏–ª, —á—Ç–æ –æ–ø—Ç–∏–º–∞–ª—å–Ω—ã–π —Ä–∞–∑–º–µ—Ä —ç–º–±–µ–¥–¥–∏–Ω–≥–∞ –æ–±—ã—á–Ω–æ —Å–≤—ã—à–µ 300."
      ],
      "metadata": {
        "id": "dLBbuIOJvfAT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "del w2v_model_neg, w2v_model_pos, results"
      ],
      "metadata": {
        "id": "WvtrDAyND0mP"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "–¢–µ–ø–µ—Ä—å –ø–æ–ø—Ä–æ–±—É–π—Ç–µ –æ–±—É—á–∏—Ç—å –ª–æ–≥–∏—Å—Ç–∏—á–µ—Å–∫—É—é –∏–ª–∏ –ª–∏–Ω–µ–π–Ω—É—é —Ä–µ–≥—Ä–µ—Å—Å–∏—é –Ω–∞ –ª—é–±—ã—Ö –¥—Ä—É–≥–∏—Ö —ç–º–±–µ–¥–¥–∏–Ω–≥–∞—Ö —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç–∏ 300 –∏ —Å—Ä–∞–≤–Ω–∏—Ç–µ –∫–∞—á–µ—Å—Ç–≤–æ —Å Word2Vec."
      ],
      "metadata": {
        "id": "f29vizrmXHaT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from gensim.models import FastText, Doc2Vec\n",
        "from gensim.models.doc2vec import TaggedDocument\n",
        "\n",
        "model_ft_pos = FastText(df_train['positive'], window=10, epochs=12, alpha=0.09, vector_size=300)\n",
        "model_ft_neg = FastText(df_train['negative'], window=10, epochs=12,  alpha=0.09, vector_size=300)\n",
        "vec1, vec2 = tfidf_vectorizer(model_ft_pos), tfidf_vectorizer(model_ft_neg)\n",
        "X, _, _ = transform_fragments(vec1, vec2, [df_train, df_test])\n",
        "_ = get_quality(X[0], y_train, X[1], y_test, alert=True, alpha=0.2)\n",
        "\n",
        "# Test MAE for Ridge: 0.9349474496674942\n",
        "# Train MAE for Ridge: 0.9270191574689883"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-02-04T19:24:58.642966Z",
          "iopub.execute_input": "2022-02-04T19:24:58.643214Z",
          "iopub.status.idle": "2022-02-04T19:30:20.315496Z",
          "shell.execute_reply.started": "2022-02-04T19:24:58.643185Z",
          "shell.execute_reply": "2022-02-04T19:30:20.314776Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gd3ak5TGvfAT",
        "outputId": "c3df993d-ed56-4e2c-e057-2cede6a885ed"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test MAE for Ridge: 0.9392109693955217\n",
            "Train MAE for Ridge: 0.9283219987028422\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "documents_pos = [TaggedDocument(doc, [i]) for i, doc in enumerate(df_train['positive'])]\n",
        "documents_neg = [TaggedDocument(doc, [i]) for i, doc in enumerate(df_train['negative'])]\n",
        "model_d2v_pos = Doc2Vec(documents_pos, window=7, epochs=15, alpha=0.05, vector_size=300)\n",
        "model_d2v_neg = Doc2Vec(documents_neg, window=7, epochs=10, alpha=0.05, vector_size=300)\n",
        "del documents_pos, documents_neg\n",
        "\n",
        "vec1, vec2 = tfidf_vectorizer(model_d2v_pos), tfidf_vectorizer(model_d2v_neg)\n",
        "X, _, _ = transform_fragments(vec1, vec2, [df_train, df_test])\n",
        "_ = get_quality(X[0], y_train, X[1], y_test, alert=True)\n",
        "\n",
        "# Test MAE for Ridge: 0.9338142101887302\n",
        "# Train MAE for Ridge: 0.9249547038064014"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-02-04T19:31:48.911855Z",
          "iopub.execute_input": "2022-02-04T19:31:48.912070Z",
          "iopub.status.idle": "2022-02-04T19:33:34.751481Z",
          "shell.execute_reply.started": "2022-02-04T19:31:48.912044Z",
          "shell.execute_reply": "2022-02-04T19:33:34.750539Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ksyvI-LyvfAT",
        "outputId": "7c39b114-3a39-4034-b6d7-cda5d02e4c05"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test MAE for Ridge: 0.9323742092343171\n",
            "Train MAE for Ridge: 0.9254249373820057\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### –í—ã–≤–æ–¥—ã:\n",
        "–ù–µ –ª—É—á—à–µ, —á–µ–º word2vec + Ridge + IGF-–≤–∑–≤–µ—à–∏–≤–∞–Ω–∏–µ. –ï—Å–ª–∏ —Å—Ä–∞–≤–Ω–∏–≤–∞—Ç—å —ç—Ç–∏ –¥–≤–∞ –º–µ—Ç–æ–¥–∞, —Ç–æ –∏–∑ –Ω–∏—Ö –ª—É—á—à–µ —Å–µ–±—è –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç IDF-–≤–∑–≤–µ—à–∏–≤–∞–Ω–∏–µ + Ridge + doc2vec."
      ],
      "metadata": {
        "id": "u6dLqWYZvfAU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "–ü—Ä–µ–¥—Å–∫–∞–∂–∏—Ç–µ –≤–∞—à–µ–π –ª—É—á—à–µ–π –º–æ–¥–µ–ª—å—é –∏–∑ —ç—Ç–æ–≥–æ –∑–∞–¥–∞–Ω–∏—è —Ç–µ—Å—Ç–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ –∏–∑ [—Å–æ—Ä–µ–≤–Ω–æ–≤–∞–Ω–∏—è](https://www.kaggle.com/t/3e8fa6cec6d048bf8e93fb72e441d88c) –∏ —Å–¥–µ–ª–∞–π—Ç–µ —Å–∞–±–º–∏—Ç. –ö–∞–∫–æ–π —É –≤–∞—Å –ø–æ–ª—É—á–∏–ª—Å—è —Å–∫–æ—Ä? –ü—Ä–∏–∫—Ä–µ–ø–∏—Ç–µ —Å–∫—Ä–∏–Ω—à–æ—Ç –∏–∑ –∫—ç–≥–≥–ª–∞."
      ],
      "metadata": {
        "id": "9AjabHMsXXBu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "submit_df = pd.read_csv(PATH_TO_TEST_DATA)\n",
        "\n",
        "X_subm, _, _ = transform_fragments(vec1, vec2, [submit_df], mode=2)\n",
        "rig = Ridge().fit(X[0], y_train)\n",
        "y_pred_rig_subm = rig.predict(X_subm[0])\n",
        "submit_df.drop(columns=['negative', 'positive'], inplace=True)\n",
        "submit_df['score'] = y_pred_rig_subm\n",
        "\n",
        "submit_df.to_csv('sumbit_2.csv', index=False)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-02-04T19:33:34.753045Z",
          "iopub.execute_input": "2022-02-04T19:33:34.753431Z",
          "iopub.status.idle": "2022-02-04T19:34:58.966554Z",
          "shell.execute_reply.started": "2022-02-04T19:33:34.753367Z",
          "shell.execute_reply": "2022-02-04T19:34:58.965923Z"
        },
        "trusted": true,
        "id": "MFZMnGJFvfAU"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "del X_subm, X, vec1, vec2, model_ft_pos, model_ft_neg, model_d2v_pos, model_d2v_neg"
      ],
      "metadata": {
        "id": "IzgWUvpTEXKO"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### –ß–∞—Å—Ç—å 3. 4 –±–∞–ª–ª–∞"
      ],
      "metadata": {
        "id": "EO5TZriLXHaT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "–¢–µ–ø–µ—Ä—å –¥–∞–≤–∞–π—Ç–µ –≤–æ—Å–ø–æ–ª—å–∑—É–µ–º—Å—è –±–æ–ª–µ–µ –ø—Ä–æ–¥–≤–∏–Ω—É—Ç—ã–º–∏ –º–µ—Ç–æ–¥–∞–º–∏ –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Ç–µ–∫—Å—Ç–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö, –∫–æ—Ç–æ—Ä—ã–µ –º—ã –ø—Ä–æ—Ö–æ–¥–∏–ª–∏ –≤ –Ω–∞—à–µ–º –∫—É—Ä—Å–µ. –û–±—É—á–∏—Ç–µ RNN/Transformer –¥–ª—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–æ–π –æ—Ü–µ–Ω–∫–∏."
      ],
      "metadata": {
        "id": "5RNngNdWXHaT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "–ï—Å–ª–∏ –±—É–¥–µ—Ç–µ –æ–±—É—á–∞—Ç—å RNN, –ø–æ–ø—Ä–æ–±—É–π—Ç–µ –æ–≥—Ä–∞–Ω–∏—á–∏—Ç—å –º–∞–∫—Å–∏–º–∞–ª—å–Ω—É—é –¥–ª–∏–Ω—É –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è. –ù–µ–∫–æ—Ç–æ—Ä—ã–µ –æ—Ç–∑—ã–≤—ã –º–æ–≥—É—Ç –±—ã—Ç—å —Å–ª–∏—à–∫–æ–º –¥–ª–∏–Ω–Ω—ã–µ –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω–æ –æ—Å—Ç–∞–ª—å–Ω—ã—Ö.\n",
        "\n",
        "–ß—Ç–æ–±—ã –ø–æ–ª—å–∑–æ–≤–∞—Ç—å—Å—è DataLoader, –≤—Å–µ –µ–≥–æ —ç–ª–µ–º–µ–Ω—Ç—ã –¥–æ–ª–∂–Ω—ã –±—ã—Ç—å –æ–¥–∏–Ω–∞–∫–æ–≤–æ–π —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç–∏. –î–ª—è —ç—Ç–æ–≥–æ –≤—ã –º–æ–∂–µ—Ç–µ –¥–æ–±–∞–≤–∏—Ç—å –Ω—É–ª–µ–≤–æ–π –ø–∞–¥–¥–∏–Ω–≥ –∫–æ –≤—Å–µ–º –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è–º (—Å–º –ø—Ä–∏–º–µ—Ä pad_sequence)"
      ],
      "metadata": {
        "id": "_8YdTedQXHaT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# pip install --upgrade torch"
      ],
      "metadata": {
        "id": "tsQLleTIAkJW"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from IPython.display import clear_output\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import torchtext\n",
        "from torch import nn\n",
        "from torch.nn import functional as F\n",
        "print(torch.__version__)"
      ],
      "metadata": {
        "id": "89Y9wsViXHaU",
        "execution": {
          "iopub.status.busy": "2022-02-04T07:31:43.632037Z",
          "iopub.execute_input": "2022-02-04T07:31:43.632373Z",
          "iopub.status.idle": "2022-02-04T07:31:43.637542Z",
          "shell.execute_reply.started": "2022-02-04T07:31:43.632333Z",
          "shell.execute_reply": "2022-02-04T07:31:43.636824Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ebeef4c9-6cef-4b03-a157-b3351a088348"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.10.2+cu102\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "–í–æ–æ–±—â–µ –≥–æ–≤–æ—Ä—è –º–æ–∂–Ω–æ –±—ã–ª–æ –±—ã —É–¥–∞–ª–∏—Ç—å —Ç–µ –æ—Ç–∑—ã–≤—ã, –≥–¥–µ –≤ –ø–æ–ª—è—Ö –ø—É—Å—Ç–æ, –∏–ª–∏ –∂–µ —Å –∑–∞–ø–æ–ª–Ω–µ–Ω–∏—è–º–∏ –∞-–ª—è `no positive`/`no negative`. –õ—é–¥–∏ —Å–∫–ª–æ–Ω–Ω—ã –Ω–∏—á–µ–≥–æ –Ω–µ –ø–∏—Å–∞—Ç—å –∏ —Å—Ç–∞–≤–∏—Ç—å –≤—ã—Å–æ–∫–∏–µ –æ—Ü–µ–Ω–∫–∏, –ª–∏–±–æ –∂–µ –ø–∏—Å–∞—Ç—å `no positive` –∏ —Å—Ç–∞–≤–∏—Ç—å 0 –∏–ª–∏, –Ω–∞–ø—Ä–æ—Ç–∏–≤, –ø–∏—Å–∞—Ç—å `no negative` –∏ —Å—Ç–∞–≤–∏—Ç—å 10. –ü–æ—ç—Ç–æ–º—É —è —Ä–µ—à–∏–ª –Ω–∏—á–µ–≥–æ –Ω–µ —É–¥–∞–ª—è—Ç—å - —Ç–∞–∫–∏–µ –¥–∞–Ω–Ω—ã–µ –º–æ–≥—É—Ç —Å–∏–ª—å–Ω–æ –≤–ª–∏—è—Ç—å –Ω–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç."
      ],
      "metadata": {
        "id": "RjtleSFOvfAW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## BERT Fine-Tuning"
      ],
      "metadata": {
        "id": "8KrXqRE6vfAW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "–Ø –±—É–¥—É —Ä–µ—à–∞—Ç—å –∑–∞–¥–∞—á—É —Ä–µ–≥—Ä–µ—Å—Å–∏–∏, –∏ –≤ —Ç–∞–∫–∏—Ö —Å–ª—É—á–∞—è—Ö –ø—Ä–∏–Ω—è—Ç–æ —Å–∫–∞–ª–∏—Ä–æ–≤–∞—Ç—å —Ü–µ–ª–µ–≤—É—é –ø–µ—Ä–µ–º–µ–Ω–Ω—É—é."
      ],
      "metadata": {
        "id": "fNxJ2ffnvfAX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "cqW7tXo_Bbs3"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "PATH_TO_TRAIN_DATA = 'drive/MyDrive/data/train.csv'\n",
        "PATH_TO_TEST_DATA = 'drive/MyDrive/data/test.csv'\n",
        "\n",
        "df = pd.read_csv(PATH_TO_TRAIN_DATA)\n",
        "data = df['positive'] + ' ' + df['negative']\n",
        "df_train, df_test, y_train, y_test = train_test_split(data, df['score'], random_state=1412)\n",
        "\n",
        "scaler = StandardScaler().fit(y_train.to_numpy().reshape(-1, 1))\n",
        "y_train_ = scaler.transform(y_train.to_numpy().reshape(-1, 1))\n",
        "y_test_ = scaler.transform(y_test.to_numpy().reshape(-1, 1))"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-02-04T20:31:21.944130Z",
          "iopub.execute_input": "2022-02-04T20:31:21.944416Z",
          "iopub.status.idle": "2022-02-04T20:31:21.953153Z",
          "shell.execute_reply.started": "2022-02-04T20:31:21.944387Z",
          "shell.execute_reply": "2022-02-04T20:31:21.952208Z"
        },
        "trusted": true,
        "id": "3B3hOVQXvfAX"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### –¢–æ–∫–µ–Ω–∏–∑–∞—Ü–∏—è –∏ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö"
      ],
      "metadata": {
        "id": "onqU8Q2lpsD0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "–ü—Ä–æ—á–∏—Ç–∞–≤ –Ω–µ—Å–∫–æ–ª—å–∫–æ —Å—Ç–∞—Ç–µ–π, —è –ø–æ–Ω—è–ª, —á—Ç–æ –Ω—É–∂–Ω–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –≤—Å—Ç—Ä–æ–µ–Ω–Ω—ã–µ –º–µ—Ç–æ–¥—ã —ç–º–±–µ–¥–¥–∏–Ω–≥–∞:\n",
        "- \"We can‚Äôt use the pre-tokenized version because, in order to apply the pre-trained BERT, we must use the tokenizer provided by the model. This is because (1) the model has a specific, fixed vocabulary and (2) the BERT tokenizer has a particular way of handling out-of-vocabulary words.\"\n",
        "\n",
        "- \"Common embedding approaches in NLP such as Word2Vec or FastText usually require lemmatization and stop words to be removed, but this is not the case for BERT. The general structure of the text should actually not be modified since BERT relies on it to learn and interpret context.\"\n",
        "\n",
        "–ö–∞–∫ –≤–æ–æ–±—â–µ —è —Ö–æ—Ç–µ–ª –±—ã –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞—Ç—å –¥–∞–Ω–Ω—ã–µ: –æ—Ç–¥–µ–ª—å–Ω–æ –ª–µ–º–º–∞—Ç–∏–∑–∏—Ä—É–µ–º –∏ —Ç–æ–∫–µ–Ω–∏–∑–∏—Ä—É–µ–º —Å—Ç–æ–ª–±—Ü—ã `positive` –∏ `negative`, –ø–æ–ª—É—á–∞–µ–º —Ç–µ–Ω–∑–æ—Ä—ã, –∑–∞—Ç–µ–º –∫–æ–Ω–∫–∞—Ç–µ–Ω–∏—Ä—É–µ–º. –ú–æ–∂–Ω–æ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤—ã–≤–∞—Ç—å –ø—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω–æ —Å–∫–æ–Ω–∫–∞—Ç–µ–Ω–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ —Ç–µ–∫—Å—Ç—ã –æ—Ç–∑—ã–≤–æ–≤, –∞ –∑–∞—Ç–µ–º —Ç–æ–∫–µ–Ω–∏–∑–∏—Ä–æ–≤–∞—Ç—å. –í –ø–µ—Ä–≤–æ–º —Å–ª—É—á–∞–µ –ø—Ä–∏–¥–µ—Ç—Å—è —É—á–∏—Ç—å –¥–≤–µ –º–æ–¥–µ–ª–∏ –∏ –∫–∞–∫–∏–º-—Ç–æ –æ–±—Ä–∞–∑–æ–º –∞—Å—Å–µ–º–±–ª–∏—Ä–æ–≤–∞—Ç—å, –ø–æ—ç—Ç–æ–º—É —è —Å–∫–ª–æ–Ω—è—é—Å—å –∫–æ –≤—Ç–æ—Ä–æ–º—É –≤–∞—Ä–∏–∞–Ω—Ç—É, —Ö–æ—Ç—å –∏ —Å—á–∏—Ç–∞—é –µ–≥–æ –Ω–µ —Å–æ–≤—Å–µ–º –ø—Ä–∞–≤–∏–ª—å–Ω—ã–º."
      ],
      "metadata": {
        "id": "J0U_eOysvfAX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "–ü—Ä–∏–≤–æ–∂—É –≤—ã–¥–µ—Ä–∂–∫–∏ –∏–∑ –Ω–µ–∫–æ—Ç–æ—Ä—ã—Ö –ø—Ä–æ—á–∏—Ç–∞–Ω–Ω—ã—Ö —Å—Ç–∞—Ç–µ–π. –ó–¥–µ—Å—å –æ–ø–∏—Å—ã–≤–∞—é—Ç—Å—è —Å–ø–µ—Ü–∏–∞–ª—å–Ω—ã–µ —Ç–æ–∫–µ–Ω—ã –∏ –≤ –∫–∞–∫–æ–º –≤–∏–¥–µ –º—ã –¥–æ–ª–∂–Ω—ã –ø–æ–¥–∞–≤–∞—Ç—å –¥–∞–Ω–Ω—ã–µ –Ω–∞ –≤—Ö–æ–¥ –º–æ–¥–µ–ª–∏.\n",
        "\n",
        "We are required to:\n",
        "\n",
        "* Add special tokens to the start and end of each sentence.\n",
        "* Pad & truncate all sentences to a single constant length.\n",
        "* Explicitly differentiate real tokens from padding tokens with the ‚Äúattention mask‚Äù.\n",
        "\n",
        "\n",
        "[SEP]\n",
        "\n",
        "At the end of every sentence, we need to append the special [SEP] token.\n",
        "\n",
        "This token is an artifact of two-sentence tasks, where BERT is given two separate sentences and asked to determine something (e.g., can the answer to the question in sentence A be found in sentence B?).\n",
        "\n",
        "I am not certain yet why the token is still required when we have only single-sentence input, but it is!\n",
        "\n",
        "[CLS]\n",
        "\n",
        "For classification tasks, we must prepend the special [CLS] token to the beginning of every sentence.\n",
        "\n",
        "This token has special significance. BERT consists of 12 Transformer layers. Each transformer takes in a list of token embeddings, and produces the same number of embeddings on the output (but with the feature values changed, of course!).\n",
        "\n",
        "\n",
        "\\\\\n",
        "BERT takes as input sequences of equal length. Input sequences must thus be padded or truncated at a given length with special characters explicitly indicating the actual start and end of the sequence. The special start character is referred to as the ‚Äú[CLS]‚Äù token.\n",
        "These input sequences are then split into two :\n",
        "- A sequence of ‚Äúinput ids‚Äù, mapping the words to tokens from the vocabulary the model was pre-trained with,\n",
        "- A binary sequence of ‚Äúattention masks‚Äù that indicate whether the ‚Äúinput id‚Äù at a given index is a word or padding."
      ],
      "metadata": {
        "id": "plYEXdAponJP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# pip install transformers"
      ],
      "metadata": {
        "id": "AwM6TaoP1w9j"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BertTokenizer\n",
        "from transformers import BertModel, BertConfig\n",
        "model_name = \"bert-base-uncased\""
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-02-04T21:36:53.097344Z",
          "iopub.execute_input": "2022-02-04T21:36:53.100899Z",
          "iopub.status.idle": "2022-02-04T21:36:53.110729Z",
          "shell.execute_reply.started": "2022-02-04T21:36:53.100786Z",
          "shell.execute_reply": "2022-02-04T21:36:53.109888Z"
        },
        "trusted": true,
        "id": "euOB0OBGvfAX"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "–í–∞–∂–Ω–æ –ø–æ–¥–æ–±—Ä–∞—Ç—å –º–∞–∫—Å–∏–º–∞–ª—å–Ω—É—é –¥–ª–∏–Ω—É –≤—Ö–æ–¥–Ω–æ–π –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç—å `max_length`. –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ –¥–æ–ø—É—Å—Ç–∏–º–æ –¥–ª—è –º–æ–¥–µ–ª–∏ - 512, –ø–æ—ç—Ç–æ–º—É –ø–æ—Å—á–∏—Ç–∞–µ–º –¥–ª–∏–Ω—ã –∏ –ø–æ—Å–º–æ—Ç—Ä–∏–º, —Å–∫–æ–ª—å–∫–æ —É –Ω–∞—Å –æ—Ç–∑—ã–≤–æ–≤, –ø—Ä–µ–≤—ã—à–∞—é—â–∏—Ö —ç—Ç–æ—Ç –ø–æ—Ä–æ–≥."
      ],
      "metadata": {
        "id": "1iPUEV20vfAX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tkn = BertTokenizer.from_pretrained(model_name, do_lower_case=True)\n",
        "def define_max_length(dataframe):\n",
        "    \n",
        "    tmp_data = np.array(tkn(dataframe.tolist(), return_length=True)['length'])\n",
        "    # –±–µ—Ä–µ–º 510, —Ç–∞–∫ –∫–∞–∫ —É –Ω–∞—Å –≤ –∑–∞–ø–∞—Å–µ –¥–≤–∞ —Å–ø–µ—Ü–∏–∞–ª—å–Ω—ã—Ö —Ç–æ–∫–µ–Ω–∞ - –Ω–∞—á–∞–ª–∞ –∏ –∫–æ–Ω—Ü–∞ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏\n",
        "    inds = np.argwhere(tmp_data > 510)\n",
        "    count = len(inds)\n",
        "    max_length = np.max(tmp_data[inds])\n",
        "    return max_length, count, inds.reshape(-1)\n",
        "\n",
        "train = define_max_length(df_train)\n",
        "test = define_max_length(df_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mp5w1dPFQkGL",
        "outputId": "c8815961-a304-4950-e0b5-af2870765259"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Token indices sequence length is longer than the specified maximum sequence length for this model (513 > 512). Running this sequence through the model will result in indexing errors\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('For train set:\\n\\tMax Length %.2f\\n\\tCount: %.2f' % (train[0], train[1]))\n",
        "print('For test set:\\n\\tMax Length %.2f\\n\\tCount: %.2f' % (test[0], test[1]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xOnYZ2FASGJu",
        "outputId": "843c1ef9-74a5-4853-fb26-d78ca5e728f3"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "For train set:\n",
            "\tMax Length 663.00\n",
            "\tCount: 10.00\n",
            "For test set:\n",
            "\tMax Length 519.00\n",
            "\tCount: 1.00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "–î–æ–ª—è —Ç–∞–∫–∏—Ö –æ—Ç–∑—ã–≤–æ–≤ –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω–æ —á–∏—Å–ª–∞ –æ–±—ä–µ–∫—Ç–æ–≤ –≤ –¥–∞—Ç–∞—Å–µ—Ç–∞—Ö –∫—Ä–∞–π–Ω–µ –º–∞–ª–∞, –ø–æ—ç—Ç–æ–º—É —è –ø—Ä–µ–¥–ª–∞–≥–∞—é –∏—Ö –≤—ã–∫–∏–Ω—É—Ç—å."
      ],
      "metadata": {
        "id": "s-UMLp4lV7WS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "check_ind = train[2][1]\n",
        "print(y_train_[check_ind-1], y_train_[check_ind], y_train_[check_ind+1], sep=\"\\n\")\n",
        "df_train.iloc[[check_ind-1, check_ind, check_ind+1]]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5MFApoSjWJbA",
        "outputId": "b19d6a25-b142-4977-80ff-0d4cc8a4d942"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.24375773]\n",
            "[-0.79355767]\n",
            "[-0.54948346]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "15825     Location spacious rooms  Absolutely boring br...\n",
              "20862     We drove to the Hotel and paid the extra to p...\n",
              "66693     Good location   The decor is a little tired t...\n",
              "dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_train.drop(index=df_train.index[train[2]], axis=0, inplace=True)\n",
        "df_test.drop(index=df_test.index[test[2]], axis=0, inplace=True)\n",
        "\n",
        "y_train_ = y_train_[np.setdiff1d([i for i in range(len(y_train_))], train[2])]\n",
        "y_test_ = y_test_[np.setdiff1d([i for i in range(len(y_test_))], test[2])]\n",
        "df_train.shape, df_test.shape, len(y_train_), len(y_test_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "irfTtgiTbCZ6",
        "outputId": "b6f6d253-bfa3-4495-d79d-950be242deb9"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((74990,), (24999,), 74990, 24999)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "check_ind = train[2][1]\n",
        "print(y_train_[check_ind-2], y_train_[check_ind-1], y_train_[check_ind], sep=\"\\n\")\n",
        "df_train.iloc[[check_ind-2, check_ind-1, check_ind]]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zy7UeeYTbERE",
        "outputId": "f4bd0ec8-2b16-415b-a2f0-ce639c9fb030"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.24375773]\n",
            "[-0.54948346]\n",
            "[-0.79355767]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "15825     Location spacious rooms  Absolutely boring br...\n",
              "66693     Good location   The decor is a little tired t...\n",
              "29380                          Clean room  Far from center\n",
              "dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "–í—Å–µ –û–ö. –ú–æ–∂–Ω–æ —Ç–æ–∫–µ–Ω–∏–∑–∏—Ä–æ–≤–∞—Ç—å."
      ],
      "metadata": {
        "id": "ofzpZA5qbcHg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = BertTokenizer.from_pretrained(model_name, do_lower_case=True)\n",
        "\n",
        "# output_attentions=True\n",
        "train_corpus = tokenizer(text=df_train.tolist(),\n",
        "                            add_special_tokens=True,\n",
        "                            padding='max_length',\n",
        "                            truncation='longest_first', # –º–æ–∂–Ω–æ —É–∫–∞–∑–∞—Ç—å truncation=False, –Ω–æ –ª—É—á—à–µ –Ω–µ –±—É–¥—É, –≤–¥—Ä—É–≥ –±–∞–≥–∞ –∫–∞–∫–∞—è\n",
        "                            max_length=512,\n",
        "                            return_attention_mask=True,\n",
        "                            return_tensors='pt')\n",
        "\n",
        "test_corpus = tokenizer(text=df_test.tolist(),\n",
        "                            add_special_tokens=True,\n",
        "                            padding='max_length',\n",
        "                            truncation='longest_first',\n",
        "                            max_length=512,\n",
        "                            return_attention_mask=True,\n",
        "                            return_tensors='pt')\n",
        "\n",
        "input_ids_train = train_corpus['input_ids']\n",
        "attention_mask_train = train_corpus['attention_mask']\n",
        "\n",
        "input_ids_test = test_corpus['input_ids']\n",
        "attention_mask_test = test_corpus['attention_mask']\n",
        "\n",
        "# sentence split\n",
        "# tokenizer.tokenize('str')\n",
        "# sentence mapped to token ids\n",
        "# tokenizer.convert_tokens_to_ids(tokenizer.tokenize('str))"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-02-04T21:36:58.798456Z",
          "iopub.execute_input": "2022-02-04T21:36:58.799762Z",
          "iopub.status.idle": "2022-02-04T21:37:18.919266Z",
          "shell.execute_reply.started": "2022-02-04T21:36:58.799697Z",
          "shell.execute_reply": "2022-02-04T21:37:18.917454Z"
        },
        "trusted": true,
        "id": "ufAM7sScvfAX"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_ids_train.shape, attention_mask_train.shape, input_ids_test.shape, attention_mask_test.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FSnEnAzAvfAY",
        "outputId": "7e39b7fa-7aab-422d-b8c5-0f37b54664b1"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([74990, 512]),\n",
              " torch.Size([74990, 512]),\n",
              " torch.Size([24999, 512]),\n",
              " torch.Size([24999, 512]))"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "–ö–∞–∫ –≤–∏–¥–∏–º, –¥–∞–Ω–Ω—ã–µ –±—ã–ª–∏ –ø—Ä–∏–≤–µ–¥–µ–Ω—ã –∫ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–µ–º—É –≤–∏–¥—É - –º–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–π —Ä–∞–∑–º–µ—Ä 512, –±—ã–ª–∏ –¥–æ–±–∞–≤–ª–µ–Ω—ã —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–∏–µ —Ç–æ–∫–µ–Ω—ã:"
      ],
      "metadata": {
        "id": "bn1mgVWMnDf-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_ids_train[0][:30]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "10WvRTzgnMqL",
        "outputId": "47c52591-35ed-4bc7-faad-00404bb49e46"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([  101,  2053,  3893,  1996,  2282,  2001,  4714,  1998,  1996,  3976,\n",
              "         4654, 16368, 16313,  4630,  2005,  2008,  2946,  2282,   102,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0])"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "attention_mask_train[0][:30]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I3rTZ1sBnUCL",
        "outputId": "719e9f9c-b1a8-413a-ae82-2b77a5089237"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "–ò–Ω–¥–µ–∫—Å—ã `101` –∏ `102` - —Ç–æ–∫–µ–Ω—ã –Ω–∞—á–∞–ª–∞ `[CLS]` –∏ –∫–æ–Ω—Ü–∞ `[SEP]` –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏. –ù—É–ª–∏ - —Ç–æ–∫–µ–Ω—ã –ø–∞–¥–¥–∏–Ω–≥–∞ `[PAD]`. –ï–¥–∏–Ω–∏—Ü—ã –≤ –º–∞—Å–∫–µ –≤–Ω–∏–º–∞–Ω–∏—è —Å—Ç–æ—è—Ç —Ç–∞–º, –≥–¥–µ –≤–æ–æ–±—â–µ –Ω–∞—Ö–æ–¥–∏—Ç—Å—è –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç—å, —Ç.–µ. –Ω–∞ –ø–∞–¥–¥–∏–Ω–≥–∏ –æ–Ω–∞ –Ω–µ —Ä–µ–∞–≥–∏—Ä—É–µ—Ç. –ò–Ω—ã–º–∏ —Å–ª–æ–≤–∞–º–∏ –º–∞—Å–∫–∞ –≤–Ω–∏–º–∞–Ω–∏—è –æ—Ç–ª–∏—á–∞–µ—Ç –ø–∞–¥–¥–∏–Ω–≥ –æ—Ç –æ—Å—Ç–∞–ª—å–Ω—ã—Ö —Ç–æ–∫–µ–Ω–æ–≤."
      ],
      "metadata": {
        "id": "IhSX2oyTvfAZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö"
      ],
      "metadata": {
        "id": "qSB0ITwEpla4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "\n",
        "targets_train = torch.tensor(y_train_, dtype=torch.int32)\n",
        "targets_test = torch.tensor(y_test_, dtype=torch.int32)\n",
        "\n",
        "train_dataset = TensorDataset(input_ids_train, attention_mask_train, targets_train)\n",
        "test_dataset = TensorDataset(input_ids_test, attention_mask_test, targets_test)\n",
        "\n",
        "batch_size = 16\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=2, pin_memory=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=2, pin_memory=True)"
      ],
      "metadata": {
        "id": "CgDhiiq-pyHo"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### –ú–æ–¥–µ–ª—å"
      ],
      "metadata": {
        "id": "jtpzQR_0sS5u"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "–ù–∞ –≤—ã—Ö–æ–¥–µ –ø–æ—Å–ª–µ–¥–Ω–µ–≥–æ (12-–≥–æ) —Å–ª–æ—è —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–µ—Ä–∞ –≤ –∑–∞–¥–∞—á–µ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ –¥–ª—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è —Ç–æ–ª—å–∫–æ –ø–µ—Ä–≤—ã–π —ç–º–±–µ–¥–¥–∏–Ω–≥ `[CLS]`. –í—ã–≥–ª—è–¥–∏—Ç —ç—Ç–æ [—Ç–∞–∫](http://www.mccormickml.com/assets/BERT/padding_and_mask.png). \n",
        "\n",
        "- ‚ÄúThe first token of every sequence is always a special classification token ([CLS]). The final hidden state corresponding to this token is used as the aggregate sequence representation for classification tasks,\" - –∏–∑ –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–æ–π —Å—Ç–∞—Ç—å–∏.\n",
        "\n",
        "–î–ª—è –∑–∞–¥–∞—á–∏ —Ä–µ–≥—Ä–µ—Å—Å–∏–∏ –º—ã –±—É–¥–µ–º –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –ø—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∏ —Ç–æ –∂–µ —Å–∞–º–æ–µ, –Ω–æ –º—ã –¥–æ–±–∞–≤–∏–º –ø–æ–ª–Ω–æ—Å–≤—è–∑–Ω—ã–π —Å–ª–æ–π."
      ],
      "metadata": {
        "id": "62gaLG9csVkS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class BertRegressor(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        # pre-trained BERT model\n",
        "        self.bert = BertModel.from_pretrained(model_name)\n",
        "        # FC layer for fine-tuning\n",
        "        self.regressor = nn.Sequential(\n",
        "            nn.Dropout(0.2),\n",
        "            nn.Linear(768, 1)\n",
        "        )\n",
        "\n",
        "    def forward(self, input_ids, attention_masks):\n",
        "        outputs = self.bert(input_ids, attention_masks)\n",
        "        class_label_output = outputs[1]\n",
        "        outputs = self.regressor(class_label_output)\n",
        "        return outputs"
      ],
      "metadata": {
        "id": "i3EpNVoYznhA"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda:0\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
        "\n",
        "def device_memory_info(device):\n",
        "    if device.type == 'cuda':\n",
        "        print(torch.cuda.get_device_name(0))\n",
        "        print('Memory Usage:')\n",
        "        print('Allocated:', round(torch.cuda.memory_allocated(0) / 1024 ** 3, 1), 'GB')\n",
        "        print('Cached:   ', round(torch.cuda.memory_reserved(0) / 1024 ** 3, 1), 'GB')\n",
        "\n",
        "device_memory_info(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uCEhFyh51eZ4",
        "outputId": "b26e03c3-72f4-4169-ee5e-c0c225ab6d29"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tesla K80\n",
            "Memory Usage:\n",
            "Allocated: 0.0 GB\n",
            "Cached:    0.0 GB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = BertRegressor()\n",
        "model.to(device)\n",
        "model_device = next(model.parameters()).device\n",
        "model_device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KCHC2IdyRyVd",
        "outputId": "9d496c83-dac5-453f-eed7-af81a79937ec"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda', index=0)"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device_memory_info(model_device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m6uLfnbcR2vn",
        "outputId": "11509dc2-8ab5-4cf6-d92e-8298e1d4c8a1"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tesla K80\n",
            "Memory Usage:\n",
            "Allocated: 0.4 GB\n",
            "Cached:    0.5 GB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### –û–ø—Ç–∏–º–∞–π–∑–µ—Ä, —Ñ—É–Ω–∫—Ü–∏—è –ø–æ—Ç–µ—Ä—å, –ø–ª–∞–Ω–∏—Ä–æ–≤—â–∏–∫"
      ],
      "metadata": {
        "id": "NN9d-HX-1tjX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lr=5e-5\n",
        "eps=1e-8\n",
        "epochs=3\n",
        "total_steps = len(train_loader) * epochs\n",
        "total_steps"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yx4HXry_ELcz",
        "outputId": "28671950-af87-4485-e9a0-bbe84e151fcd"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "14061"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# https://huggingface.co/docs/transformers/v4.16.2/en/main_classes/optimizer_schedules\n",
        "from transformers import AdamW, get_linear_schedule_with_warmup\n",
        "optimizer = AdamW(model.parameters(), lr=lr, eps=eps)\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=total_steps)\n",
        "criterion = nn.L1Loss(reduction='sum') # MAE"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RhFfkoA611Kl",
        "outputId": "b13f2334-8c09-446e-cd88-2363c74abbf2"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use thePyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  FutureWarning,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "–í–æ–∑–º–æ–∂–Ω—ã–µ –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä—ã:\n",
        "- `batch_size`: 16, 32\n",
        "- `lr`: 5e-5, 3e-5, 2e-5\n",
        "- `epochs`: 2, 3, 4"
      ],
      "metadata": {
        "id": "j7g4Tvl74s-N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏"
      ],
      "metadata": {
        "id": "LkTz-1QF5lJX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "–û—á–µ–Ω—å –∫–ª–∞—Å—Å–Ω–æ–π –∏–¥–µ–µ–π –±—ã–ª–æ –±—ã –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å Mixed Precision Training. –ú—ã —Ä–∞–∑–±–∏—Ä–∞–ª–∏ —ç—Ç–æ—Ç –º–µ—Ç–æ–¥ –Ω–∞ –Ω–∞ –ù–ò–°–µ, –∏ –æ–Ω –ø–æ–∑–≤–æ–ª—è–µ—Ç —É—Å–∫–æ—Ä–∏—Ç—å –æ–±—É—á–µ–Ω–∏–µ. –Ø –Ω–∞—Ç–∫–Ω—É–ª—Å—è –Ω–∞ –±–∏–±–ª–∏–æ—Ç–µ–∫—É, –∫–æ—Ç–æ—Ä–∞—è –ø–æ–∑–≤–æ–ª—è–µ—Ç —ç—Ç–æ —Å–¥–µ–ª–∞—Ç—å –ª–µ–≥–∫–æ –∏ –ø—Ä–æ—Å—Ç–æ: [–∑–¥–µ—Å—å](https://github.com/nvidia/apex).\n",
        "\n",
        "–ß–µ–ª–æ–≤–µ–∫, –∫–æ—Ç–æ—Ä—ã–π –Ω–∞–ø–∏—Å–∞–ª –∫–æ–¥ –Ω–∏–∂–µ –¥–ª—è —É—Å—Ç–∞–Ω–æ–≤–∫–∏ –±–∏–±–ª–∏–æ—Ç–µ–∫–∏ - –ø—Ä–æ—Å—Ç–æ —Å–≤—è—Ç–µ–π—à–∏–π."
      ],
      "metadata": {
        "id": "N-2Yph846EOa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# %%writefile setup.sh\n",
        "\n",
        "# git clone https://github.com/NVIDIA/apex\n",
        "# cd apex\n",
        "# pip install -v --no-cache-dir ./"
      ],
      "metadata": {
        "id": "AOSBsgq29Hq6"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !sh setup.sh"
      ],
      "metadata": {
        "id": "Q9kcXkHiLfCV"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from apex import amp"
      ],
      "metadata": {
        "id": "H_jTneAw9ecw"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "opt_level = 'O1'\n",
        "loss_scale = 128.0\n",
        "model, optimizer = amp.initialize(model, optimizer, opt_level=opt_level, loss_scale=loss_scale)"
      ],
      "metadata": {
        "id": "WtRd08Z46dgq"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "–ñ–∞–ª—å, —á—Ç–æ –≤ –Ω–∞–ª–∏—á–∏–µ –≤—Å–µ–≥–æ –æ–¥–Ω–∞ GPU, —Ç–∞–∫ –±—ã –º–æ–∂–Ω–æ –±—ã–ª–æ –∑–∞—é–∑–∞—Ç—å `DistributedDataParallel`."
      ],
      "metadata": {
        "id": "aArvYYMAO57x"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### –û–±—É—á–µ–Ω–∏–µ"
      ],
      "metadata": {
        "id": "ZoRXiukgG1Lb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.nn.utils.clip_grad import clip_grad_norm\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "def plot_graphs(metrics_dict):\n",
        "    fig, ax = plt.subplots(nrows=1, ncols=1, figsize=(18, 6))\n",
        "    ax.plot(metrics_dict['Epoch'], metrics_dict['Train Loss'], 'darkorchid', label='Train', linewidth=2)\n",
        "    ax.plot(metrics_dict['Epoch'], metrics_dict['Valid Loss'], 'crimson', label='Valid', linewidth=2)\n",
        "    ax.set_xlabel('Epoch')\n",
        "    ax.set_ylabel('Loss')\n",
        "    ax.set_title('Loss - Epoch')\n",
        "    ax.legend(shadow=False, fontsize=14)\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "def train_loop(model, optimizer, criterion, scheduler, train_loader, valid_loader, device='cpu', epochs=3):\n",
        "    metrics_dict = { 'Epoch': [i + 1 for i in range(epochs)], 'Train Loss': [], 'Valid Loss': [] }\n",
        "\n",
        "    for epoch in tqdm(range(epochs)):\n",
        "\n",
        "        model.train()\n",
        "        train_loss = 0.0\n",
        "        for batch in train_loader:\n",
        "            ids, masks, targets = tuple(t.to(device) for t in batch)\n",
        "            model.zero_grad()\n",
        "\n",
        "            outputs = model(ids, masks)           \n",
        "            loss = criterion(outputs.squeeze(), targets.squeeze())\n",
        "\n",
        "            loss.backward()\n",
        "            # with amp.scale_loss(loss, optimizer) as scaled_loss:\n",
        "            #     scaled_loss.backward()\n",
        "\n",
        "            clip_grad_norm(model.parameters(), max_norm=2)            \n",
        "            optimizer.step()\n",
        "            scheduler.step()\n",
        "            train_loss += loss.item() * len(targets)\n",
        "                \n",
        "        train_loss /= len(train_loader.dataset)\n",
        "        metrics_dict['Train Loss'].append(train_loss)\n",
        "        \n",
        "        \n",
        "        # model.eval()\n",
        "        # valid_loss = 0.0\n",
        "        # for batch_v in valid_loader:\n",
        "        #     ids_v, masks_v, target_v = tuple(t.to(device) for t in batch_v)\n",
        "\n",
        "        #     with torch.no_grad():\n",
        "        #         outputs_v = model(ids_v['input_ids'], ids_v['attention_mask'])           \n",
        "        #         loss = criterion(outputs_v.squeeze(), target_v.squeeze())\n",
        "        #     valid_loss += loss.item() * len(target_v)\n",
        "                \n",
        "        # valid_loss /= len(valid_loader.dataset)\n",
        "        # metrics_dict['Valid Loss'].append(valid_loss)\n",
        "    \n",
        "        clear_output(wait=True)\n",
        "        display(pd.DataFrame(metrics_dict))\n",
        "        \n",
        "    plot_graphs(metrics_dict)"
      ],
      "metadata": {
        "id": "H1U793qiG6Xc"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cuda.empty_cache()\n",
        "device_memory_info(device)\n",
        "# train_loop(model, optimizer, criterion, scheduler, train_loader, test_loader, device=model_device, epochs=1)\n",
        "train(model, optimizer, scheduler, criterion, 1, train_loader, model_device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 518
        },
        "id": "i7woESJBPgVH",
        "outputId": "e2366deb-4677-42f0-ef05-74c1038d156a"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tesla K80\n",
            "Memory Usage:\n",
            "Allocated: 0.4 GB\n",
            "Cached:    0.5 GB\n",
            "0\n",
            "-----\n",
            "0\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-28-260acda8059c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mdevice_memory_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# train_loop(model, optimizer, criterion, scheduler, train_loader, test_loader, device=model_device, epochs=1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscheduler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-27-a1551771a1ea>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, optimizer, scheduler, —Åriterion, epochs, train_dataloader, device, clip_value)\u001b[0m\n\u001b[1;32m     10\u001b[0m             \u001b[0mbatch_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_masks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_labels\u001b[0m \u001b[0;34m=\u001b[0m                                \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m             \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_masks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m             loss = —Åriterion(outputs.squeeze(), \n\u001b[1;32m     14\u001b[0m                              batch_labels.squeeze())\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-17-589823b4347a>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_masks)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_masks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_masks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m         \u001b[0mclass_label_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregressor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclass_label_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1004\u001b[0m             \u001b[0moutput_attentions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1005\u001b[0m             \u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1006\u001b[0;31m             \u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1007\u001b[0m         )\n\u001b[1;32m   1008\u001b[0m         \u001b[0msequence_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoder_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    590\u001b[0m                     \u001b[0mencoder_attention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    591\u001b[0m                     \u001b[0mpast_key_value\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 592\u001b[0;31m                     \u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    593\u001b[0m                 )\n\u001b[1;32m    594\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    475\u001b[0m             \u001b[0mhead_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m             \u001b[0moutput_attentions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 477\u001b[0;31m             \u001b[0mpast_key_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself_attn_past_key_value\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    478\u001b[0m         )\n\u001b[1;32m    479\u001b[0m         \u001b[0mattention_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself_attention_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    407\u001b[0m             \u001b[0mencoder_attention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    408\u001b[0m             \u001b[0mpast_key_value\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 409\u001b[0;31m             \u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    410\u001b[0m         )\n\u001b[1;32m    411\u001b[0m         \u001b[0mattention_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    304\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    305\u001b[0m         \u001b[0;31m# Take the dot product between \"query\" and \"key\" to get the raw attention scores.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 306\u001b[0;31m         \u001b[0mattention_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery_layer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey_layer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    307\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    308\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mposition_embedding_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"relative_key\"\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mposition_embedding_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"relative_key_query\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 11.17 GiB total capacity; 10.54 GiB already allocated; 128.81 MiB free; 10.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.train()\n",
        "train_loss = 0.0\n",
        "for batch in train_loader:\n",
        "    print(0)\n",
        "    print('------------------------------------------------------------------------------------')\n",
        "    ids, masks, targets = tuple(t.to(device) for t in batch)\n",
        "    device_memory_info(device)\n",
        "    print('------------------------------------------------------------------------------------')\n",
        "    print(1)\n",
        "    print('------------------------------------------------------------------------------------')\n",
        "    model.zero_grad()\n",
        "    device_memory_info(device)\n",
        "    print('------------------------------------------------------------------------------------')\n",
        "    print(2)\n",
        "    print('------------------------------------------------------------------------------------')\n",
        "    outputs = model(ids, masks)\n",
        "    device_memory_info(device)\n",
        "    print('------------------------------------------------------------------------------------')\n",
        "    print(3)\n",
        "    print('------------------------------------------------------------------------------------')        \n",
        "    loss = criterion(outputs.squeeze(), targets.squeeze())\n",
        "    # del outputs\n",
        "    # torch.cuda.empty_cache()\n",
        "    device_memory_info(device)\n",
        "    print('------------------------------------------------------------------------------------')\n",
        "    print(4)\n",
        "    print('------------------------------------------------------------------------------------')\n",
        "    loss.backward()\n",
        "    device_memory_info(device)\n",
        "    print('------------------------------------------------------------------------------------')\n",
        "    print(5)\n",
        "    print('------------------------------------------------------------------------------------')\n",
        "    clip_grad_norm(model.parameters(), max_norm=2)\n",
        "    device_memory_info(device)\n",
        "    print('------------------------------------------------------------------------------------')\n",
        "    print(6)\n",
        "    print('------------------------------------------------------------------------------------')\n",
        "    optimizer.step()\n",
        "    device_memory_info(device)\n",
        "    print('------------------------------------------------------------------------------------')\n",
        "    print(7)\n",
        "    print('------------------------------------------------------------------------------------')\n",
        "    scheduler.step()\n",
        "    device_memory_info(device)\n",
        "    print('------------------------------------------------------------------------------------')\n",
        "    print(8)\n",
        "    print('------------------------------------------------------------------------------------')\n",
        "    train_loss += loss.item() * len(targets)\n",
        "    device_memory_info(device)\n",
        "    print('------------------------------------------------------------------------------------')\n",
        "    break"
      ],
      "metadata": {
        "id": "l1p1fe6aed9p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "device_memory_info(device)"
      ],
      "metadata": {
        "id": "RHo7z_5GgU7R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è"
      ],
      "metadata": {
        "id": "tfewVaphVaDq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def predict(model, dataloader, device):\n",
        "    model.eval()\n",
        "    output = []\n",
        "    for batch in dataloader:\n",
        "        batch_inputs, batch_masks = tuple(b.to(device) for b in batch)\n",
        "        with torch.no_grad():\n",
        "            output += model(batch_inputs, batch_masks).view(1,-1).tolist()[0]\n",
        "    return output"
      ],
      "metadata": {
        "id": "N5rfKxv-NRKt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "submit_df = pd.read_csv(PATH_TO_TEST_DATA)\n",
        "submit_data = submit_df['positive'] + ' ' + submit_df['negative']\n",
        "\n",
        "submit_corpus = tokenizer(text=df_test.tolist(),\n",
        "                            add_special_tokens=True,\n",
        "                            padding='max_length',\n",
        "                            truncation='longest_first',\n",
        "                            max_length=512,\n",
        "                            return_attention_mask=True,\n",
        "                            return_tensors='pt')\n",
        "\n",
        "input_ids_submit = submit_corpus['input_ids']\n",
        "attention_mask_submit = submit_corpus['attention_mask']\n",
        "input_ids_submit.shape, attention_mask_submit.shape"
      ],
      "metadata": {
        "id": "DqE3RcLQNceA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "submit_dataset = TensorDataset(input_ids_submit, attention_mask_submit)\n",
        "submit_loader = DataLoader(submit_dataset, batch_size=batch_size, shuffle=False, num_workers=2, pin_memory=True)\n",
        "\n",
        "y_pred_scaled = predict(model, submit_loader, device)\n",
        "y_pred = scaler.inverse_transform(y_pred_scaled)\n",
        "\n",
        "submit_df.drop(columns=['negative', 'positive'], inplace=True)\n",
        "submit_df['score'] = y_pred\n",
        "submit_df.to_csv('transformer_sumbit.csv', index=False)"
      ],
      "metadata": {
        "id": "_mPQ8eeJYlKC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### –ö–æ–Ω—Ç–µ—Å—Ç (–¥–æ 3 –±–∞–ª–ª–æ–≤)\n",
        "\n",
        "–ü–æ –∏—Ç–æ–≥–∞–º –≤—Å–µ—Ö –≤–∞—à–∏—Ö —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–æ–≤ –≤—ã–±–µ—Ä–∏—Ç–µ –º–æ–¥–µ–ª—å, –∫–æ—Ç–æ—Ä—É—é —Å—á–∏—Ç–∞–µ—Ç–µ –ª—É—á—à–µ–π. –°–¥–µ–ª–∞–π—Ç–µ —Å–∞–±–º–∏—Ç –≤ –∫–æ–Ω—Ç–µ—Å—Ç. –í –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç –≤–∞—à–µ–≥–æ —Å–∫–æ—Ä–∞ –Ω–∞ –ø—É–±–ª–∏—á–Ω–æ–º –ª–∏–¥–µ—Ä–±–æ—Ä–¥–µ, –º—ã –Ω–∞—á–∏—Å–ª–∏–º –≤–∞–º –±–∞–ª–ª—ã:\n",
        "\n",
        " - <0.76 - 3 –±–∞–ª–ª–∞\n",
        " - [0.76; 0.78) - 2 –±–∞–ª–ª–∞\n",
        " - [0.78; 0.8) - 1 –±–∞–ª–ª"
      ],
      "metadata": {
        "id": "n3OeNQkoXHaW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "jfORFaucXHaW"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}